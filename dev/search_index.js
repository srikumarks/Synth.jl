var documenterSearchIndex = {"docs":
[{"location":"wt/#Wavetable-synthesis","page":"Wavetable synthesis","title":"Wavetable synthesis","text":"","category":"section"},{"location":"wt/","page":"Wavetable synthesis","title":"Wavetable synthesis","text":"Common synthesis technique used in sampling synths.","category":"page"},{"location":"wt/","page":"Wavetable synthesis","title":"Wavetable synthesis","text":"Synth.wavetable\nSynth.maketable\nSynth.register!","category":"page"},{"location":"wt/#Synth.wavetable","page":"Wavetable synthesis","title":"Synth.wavetable","text":"wavetable(table :: AbstractVector{Float32}, amp :: Signal, phase :: Signal)\nwavetable(s :: Sample, amp :: Signal, phase :: Signal)\nwavetable(s :: Sample, amp :: Signal, freq :: Real)\nwavetable(s :: Sample, amp :: Real, freq :: Real)\n\nA simple wavetable synth that samples the given table using the given phasor and scales the table by the given amplitude modulator. A copy of the given table is stored. If you already have a Synth.Sample, you can use its samples by passing it in directly. The sample's loop settings are not used in this case.\n\nThe wavetable is a simple array of samples, often in the same sampling rate as the output audio end point, but not necessarily so. The phase signal, which can be generated using phasor, has values in the range 01 with 0 mapping to the start of the wave table and 1 to the end. To be precise, if the wave table has N samples, then the phase values in the range 01N) will map to the first sample at index 1 and the sample at index k will be chosen by phase value in the range (k-1)N kN).\n\nThe wavetable processor does 4-point interpolation. This means you can take a small sample table and stretch it out using the interpolation by using a slowly varying phasor. This is how the \"pitch\" of the sample gets changed during synthesis.\n\nThe amplitude modulation is just as with oscil.\n\nThe samples wave table is deemed to be completed when the phasor signal or the amplitude modulator signal are completed.\n\nnote: Envelopes\nIt is common for the output of such a wavetable \"voice\" to be modulated using an envelope like adsr. You can therefore pass such an ADSR signal as the amp argument. If the phase signal is infinite in extent, then the lifetime of the wavetable voice will become determined by the lifetime of the ADRS envelope.\n\nnote: Attack and release\nA complete voice implementation using a wavetable synth will need some extra niceties like a leading fragment of sound used during the \"attack\" phase of the voice until the voice begins to systain, and perhaps switching to a different voice during the release phase with a bit of cross fade. The current implementation provides a primitive that can be composed with other units in order to make such a more complete voice. The complexity of computing this voice will then be a bit more than the basic wavetable voice, but not much more than if you'd hand coded it yourself, thanks to Julia.\n\nnote: Sustain loop\nThe phasor determines the section of the wavetable that is looped. To loop without a glitch (which can result in many undesirable harmonics), the value and slope at the start and end of the looping section will usually have to be matched. For some kinds of samples, this can be accomplished by putting the wavtable output through an appropriate low pass filter (using lpf), but it is even better to do the alignment and filter the result.\n\n\n\n\n\nwavetable(name :: Symbol, amp, freq)\n\nUses the named table. See Synth.register!.\n\n\n\n\n\n","category":"function"},{"location":"wt/#Synth.maketable","page":"Wavetable synthesis","title":"Synth.maketable","text":"maketable(L :: Int, f)\n\nUtility function to construct a table for use with wavetable. f is passed values in the range [0.0,1.0] to construct the table of the given length L.\n\n\n\n\n\n","category":"function"},{"location":"start/#Getting-started","page":"Getting started","title":"Getting started","text":"","category":"section"},{"location":"start/#Installation","page":"Getting started","title":"Installation","text":"","category":"section"},{"location":"start/","page":"Getting started","title":"Getting started","text":"Assuming you have Julia 1.11.0 or later installed, you can add the package directly from the GitHub URL.","category":"page"},{"location":"start/","page":"Getting started","title":"Getting started","text":"> ]\npkg> add https://github.com/srikumarks/Synth.jl","category":"page"},{"location":"start/#Playing-a-tone","page":"Getting started","title":"Playing a tone","text":"","category":"section"},{"location":"start/","page":"Getting started","title":"Getting started","text":"# julia -t 4,1\n> using Synth\n> play(oscil(0.25, 440.0), 2.0)","category":"page"},{"location":"start/","page":"Getting started","title":"Getting started","text":"The above plays a 440Hz tone with an amplitude of 0.25 for 2.0 seconds. Here, oscil computes a \"process\" that, over time, will produce samples that constitute a sine tone. The argument 0.25 and 440.0 are also to be interpreted as such processes. This means they can also potentially vary over time, for example, like this - ","category":"page"},{"location":"start/","page":"Getting started","title":"Getting started","text":"> play(oscil(0.25, 440.0 + oscil(100.0, 10.0)), 2.0)","category":"page"},{"location":"start/","page":"Getting started","title":"Getting started","text":"... which will give you an FM siren. The usual *, +, - operators are supported for such \"signal processes\". The rest of this \"getting started\" applies to all such processes, called Signals in this package.","category":"page"},{"location":"start/#Rendering-audio-to-a-buffer","page":"Getting started","title":"Rendering audio to a buffer","text":"","category":"section"},{"location":"start/","page":"Getting started","title":"Getting started","text":"To render the same 440Hz sine tone to a Float32 buffer,","category":"page"},{"location":"start/","page":"Getting started","title":"Getting started","text":"> v = render(oscil(0.25, 440.0), 2.0)\n96000-frame, 1-channel SampleBuf{Float32, 1}\n2.0s sampled at 48000.0Hz\n▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆","category":"page"},{"location":"start/#Saving-audio-to-a-raw-float32-file","page":"Getting started","title":"Saving audio to a raw float32 file","text":"","category":"section"},{"location":"start/","page":"Getting started","title":"Getting started","text":"> write(\"rawfile.float32\", oscil(0.25, 440.0), 2.0)","category":"page"},{"location":"start/","page":"Getting started","title":"Getting started","text":"The written data will be rescaled according to the passed rescaling settings. In this case, the default scale of 0.5 is used.","category":"page"},{"location":"start/#Reading-audio-from-a-raw-float32-file","page":"Getting started","title":"Reading audio from a raw float32 file","text":"","category":"section"},{"location":"start/","page":"Getting started","title":"Getting started","text":"> v = read_rawaudio(\"rawfile.float32\")","category":"page"},{"location":"start/","page":"Getting started","title":"Getting started","text":"v will be a Vector{Float32}.","category":"page"},{"location":"start/","page":"Getting started","title":"Getting started","text":"You can also use the load function from FileIO / LibSndFile which will return a SampleBuf from supported audio file formats. To get support for audio file formats via LibSndFile and MP3, import those packages separately. This is done so that if you don't need those, then there are fewer dependencies to deal with.","category":"page"},{"location":"stereo/#Stereo-signals","page":"Stereo signals","title":"Stereo signals","text":"","category":"section"},{"location":"stereo/","page":"Stereo signals","title":"Stereo signals","text":"The primary entities this package deals with are mono signals. However, some basic support for stereo signals is included as well using the stereo operator that clubs two mono signals to make a stereo signal. Such a \"stereo\" signal behaves like the mixed version when used as an ordinary Signal. However there are other methods that support various operations, including rendering to stereo.","category":"page"},{"location":"stereo/","page":"Stereo signals","title":"Stereo signals","text":"Pick the left/right/mixed channels of a stereo signal using left, right and [mono])@ref). Pan a mono or stereo signal left/right using pan.","category":"page"},{"location":"stereo/","page":"Stereo signals","title":"Stereo signals","text":"Synth.stereo\nSynth.left\nSynth.right\nSynth.mono\nSynth.pan","category":"page"},{"location":"stereo/#Synth.stereo","page":"Stereo signals","title":"Synth.stereo","text":"stereo(left :: SignalWithFanout, right :: SignalWithFanout)\nstereo(left :: Signal, right :: Signal)\n\nMakes a \"stereo signal\" with the given left and right channel signals. The stereo signal is itself considered a signal which produces the mixed output of the left and right channels. However, you can pick out the left and right channels separately using left and right which produce fanout versions of the two components.\n\nnote: Aliasability\nStereo signals are fanout without calling fanout on them. The first method assumes that you're passing in fanout signals (recommended). The second will make them fanout, before storing a reference, so you should subsequently access the individual channels only via the left and right methods.\n\nThere is a new value method that works on stereo signals –\n\nvalue(s::Stereo{L,R}, chan::Int, t, dt)\n\nwhere chan can be -1 for left, 0 for mixed middle and 1 for right channels. Note that calling value for different channels at the same time won't compute multiple times because Stereo is fanout directly.\n\nThe mixer and modulator operators (+/-/*) treat stereo signals as stereo and work accordingly. The other operators all (unless noted) are not cognizant of stereo signals and so you must be explicit with them if you're applying them on stereo signals.\n\nSee also: left, right and mono\n\n\n\n\n\n","category":"function"},{"location":"stereo/#Synth.left","page":"Stereo signals","title":"Synth.left","text":"left(s :: Stereo)\nleft(s :: Signal)\n\nPicks the left channel of a stereo signal. Evaluates to the signal itself if passed a non-stereo signal (which is considered mono).\n\nSee also: right, mono and stereo\n\n\n\n\n\n","category":"function"},{"location":"stereo/#Synth.right","page":"Stereo signals","title":"Synth.right","text":"right(s :: Stereo)\nright(s :: Signal)\n\nPicks the right channel of a stereo signal. Evaluates to the signal itself if passed a non-stereo signal (which is considered mono).\n\nSee also: left, mono and stereo\n\n\n\n\n\n","category":"function"},{"location":"stereo/#Synth.mono","page":"Stereo signals","title":"Synth.mono","text":"mono(s :: Stereo)\nmono(s :: Stereo, panval :: Union{Real,Signal})\nmono(s :: Signal)\n\nConverts a stereo signal into a mono signal by mixing the left and right channels. Evaluates to the signal itself if passed a non-stereo signal (which is considered mono).\n\nIn the version that takes a pan value, passing 1.0f0 will result in only the right channel being selected. Passing -1.0f0 will result in only the left channel being selected and intermediate values will linearly mix the two channels. You can think of the panval argument as where your ear is  being directed. If you direct it to the right, you hear the right channel, and if you direct it to the left, you hear the left channel sound.\n\nSee also: left, right and stereo\n\n\n\n\n\n","category":"function"},{"location":"stereo/#Synth.pan","page":"Stereo signals","title":"Synth.pan","text":"pan(s :: Signal, lr :: Real)\npan(s :: Signal, lr :: Signal)\npan(s :: Stereo{L,R}, lr :: Real) where {L,R}\n\nPans a mono signal left or right to produce a stereo signal. lr is a signal that takes values in the range [-1.0,1.0] where negative values indicate left and positive values indicate right. So giving 0.0 will centre pan the signal with left and right components receiving equal contributions of the signal.\n\nWhen applied to a stereo signal, a \"left pan\" (lr in range [-1,0]) will result in the right signal being moved left  and a \"right pan\" (lr in range [0,1]) will result in the left signal being moved right.\n\n\n\n\n\n","category":"function"},{"location":"gran/#Granular-synthesis","page":"Granular synthesis","title":"Granular synthesis","text":"","category":"section"},{"location":"gran/","page":"Granular synthesis","title":"Granular synthesis","text":"A popular cool synthesis technique that can use sampling to produce a wide variety of rich and complex sounds. A phasor is used to trigger grains on the negative edge.","category":"page"},{"location":"gran/","page":"Granular synthesis","title":"Granular synthesis","text":"granulate is the main synthesis routine that takes as \"granulator\" function like simplegrains or chorusgrains.","category":"page"},{"location":"gran/","page":"Granular synthesis","title":"Granular synthesis","text":"Synth.granulate\nSynth.simplegrains\nSynth.chorusgrains\nSynth.Granulation\nSynth.Grain","category":"page"},{"location":"gran/#Synth.granulate","page":"Granular synthesis","title":"Synth.granulate","text":"granulate(samples, dur :: Real, overlap :: Real, speed :: Real, graintime,\n          player = phasor(1.0 * speed / (dur * (1.0 - overlap)))\n          ; samplingrate=48000.0f0)\ngranulate(samples::Vector{Float32}, granulator, speed::Signal, graintime::Signal, player::Signal; samplingrate=48000.0f0)\n\nGranular synthesis - simple version.\n\nThe granulator is a function of time that returns a vector of grains. Two built-in granulators are available – simplegrains and chorusgrains. The player is expected to be a phasor which will trigger grains on the negative edge.\n\nExample\n\n    snd = read_rawaudio(\"/tmp/somefile.raw\")\n    stop = play(0.5 * granulate(snd, \n                             chorusgrains(rng,0.0,3,4.0),\n                             konst(0.5),\n                             line(0.0, 10.0, 3.2),\n                             phasor(20.0)),\n             10.0)\n\n\n\n\n\n","category":"function"},{"location":"gran/#Synth.simplegrains","page":"Granular synthesis","title":"Synth.simplegrains","text":"simplegrains(dur :: Real, overlap :: Real, speedfactor :: Real)\n\nResult is a function(time) which when called will produce a vector of a single grain. This kind of a function is what we call a \"granulator\" (see granulate).\n\n\n\n\n\n","category":"function"},{"location":"gran/#Synth.chorusgrains","page":"Granular synthesis","title":"Synth.chorusgrains","text":"chorusgrains(rng, delayspread=0.0, N=1, spread=5.0f0)\n\nResult is a function(time) which when called will produce a vector of N grains spread in time. Since the chorus spread has some randomness to it, you need to pass an RNG. This kind of function is called a \"granulator\" (see granulate).\n\n\n\n\n\n","category":"function"},{"location":"gran/#Synth.Granulation","page":"Granular synthesis","title":"Synth.Granulation","text":"Represents a granulation of a sample array.\n\nThe grain durations, overlaps and playback speed can be varied with time as signals. Additionally, the grainplayphasor is  expected to be a phasor that will trigger a new grain voice upon its negative edge.\n\n\n\n\n\n","category":"type"},{"location":"gran/#Synth.Grain","page":"Granular synthesis","title":"Synth.Grain","text":"An internal structure used to keep track of a single granular \"voice\".\n\nrt is the time within the grain. 0.0 is the start of the grain.\ngt is the grain start time within the larger sample array.\ndur is the grain duration in seconds\noverlap is also a duration in seconds. The total duration of the grain  is dependent on both dur and overlap.\n\n\n\n\n\n","category":"type"},{"location":"basic/#Basic-signals","page":"Basic signals","title":"Basic signals","text":"","category":"section"},{"location":"basic/","page":"Basic signals","title":"Basic signals","text":"These are commonly used operators that either make signals directly or transform signals in some way. Some key concepts to pay attention to include fanout and feedback.","category":"page"},{"location":"basic/","page":"Basic signals","title":"Basic signals","text":"Synth.konst\nSynth.clip\nSynth.sigfun\nSynth.fanout\nSynth.feedback\nSynth.connect\nSynth.clock\nSynth.clock_bpm\nSynth.clamp\nSynth.mix\nSynth.modulate\nSynth.krate","category":"page"},{"location":"basic/#Synth.konst","page":"Basic signals","title":"Synth.konst","text":"konst(v::Real)\n\nMakes a constant valued signal. Useful with functions that accept signals but we only want to use a constant value for it.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.clip","page":"Basic signals","title":"Synth.clip","text":"clip(dur :: Float64, s :: Signal)\n\nClips the given signal to the given duration. Usually you'd use a \"soft\" version of this like a raised cosine or ADSR, but clip could be useful on its own.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.sigfun","page":"Basic signals","title":"Synth.sigfun","text":"sigfun(f::Function) :: SigFun\n\nTreats a simple function of time (in seconds) as a signal.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.fanout","page":"Basic signals","title":"Synth.fanout","text":"fanout(s :: Signal)\n\nA signal, once constructed, can only be used by one \"consumer\" via structure composition. In some situations, we want a signal to be plugged into multiple consumers (to make a signal flow DAG). For these occasions, make the signal fanout by calling fanout on it and use the aliasble signal everywhere you need it instead. Note that fanout is an idempotent operator (i.e. if s = fanout(sig), then fanout(s) = s).\n\nnote: Constraint\nIt only makes sense to make a single fanout version of a signal. Repeated evaluation of a signal is avoided by fanout by storing the recently computed value for a given time. So it assumes that time progresses linearly.\n\nnote: Terminology\nThe word \"alias\" has two meanings - one in the context of signals where frequency shifting it can cause wrap around effects in the spectrum due to sampling, and in the context of a programming language where a value referenced in multiple data structures is said to be \"aliased\". It is in the latter sense that we use the word fanout in this case. \n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.feedback","page":"Basic signals","title":"Synth.feedback","text":"feedback()\n\nConstructs a feedback node which can be connected to a signal later on after construction. This is intended to be used in feedback loops and introduces a single sample delay to prevent infinite recursion.\n\nYou can later on connect a signal to the feedback point by calling connect(::Signal,::Feedback). Just as fanout is used to make DAG signal flow graphs possible, feedback is used to make graphs with loops possible.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.connect","page":"Basic signals","title":"Synth.connect","text":"connect(s :: Signal, fb :: Feedback)\n\nConnects a signal to a feedback point.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.clock","page":"Basic signals","title":"Synth.clock","text":"clock(speed :: Real, t_end :: Real = Inf)\nclock(speed :: Signal, t_end :: Real = Inf)\n\nConstructs different kinds of clocks. Clocks can be speed controlled. Clocks used for audio signals should be made using the clock constructor and those for scheduling purposes using clock_bpm.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.clock_bpm","page":"Basic signals","title":"Synth.clock_bpm","text":"clock_bpm(tempo_bpm=60.0, t_end :: Real = Inf) :: Signal\nclock_bpm(tempo_bpm :: Signal, t_end :: Real = Inf) :: Signal\n\nConstructs different kinds of clocks. Clocks can be speed controlled. Clocks used for audio signals should be made using the clock constructor and those for scheduling purposes using clock_bpm.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Base.clamp","page":"Basic signals","title":"Base.clamp","text":"clamp(sig::Signal, minval::Real, maxval::Real)\nclamp(sig::Stereo{L,R}, minval::Real, maxval::Real) where {L <: Signal, R <: Signal}\n\nClamps the given signal to the give minimum and maximum values.  Supports stereo signals and clamps the individual channels.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.mix","page":"Basic signals","title":"Synth.mix","text":"mix(w1 :: Real, s1 :: Signal, w2 :: Real, s2 :: Signal)\n\nCreates a mixed signal from the two given signals, using the two  constant weights. This is the basis of the support for + and - between signals. This and modulate remove some unnecessary combinations and reduce them down to simpler forms where possible.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.modulate","page":"Basic signals","title":"Synth.modulate","text":"modulate(m :: Signal, s :: Signal)\n\nBasically performs multiplication between two signals and is the basis of * operator support. This and mix together implement some expression simplifications that remove unnecessary combinations.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.krate","page":"Basic signals","title":"Synth.krate","text":"krate(rate_hz :: Float64, s :: Signal)\n\nShort for \"control-rate limited\" signal. Useful with signals that vary slowly but are computationally expensive to do at audio rates. Same idea as in the original CSound and in many audio synthesis kits.\n\nProduces a signal that will evaluate the given signal at a much lower sampling interval and linearly interpolate between the values to reduce computation. The given signal will effectively be \"sampled\" at the lower given interval. For example, krate(100.0, oscil(0.5f0, 10.0f0)) will construct a 10Hz sine that is sampled only 100 times a second and interpolated, instead of having to  calculate sines 48000 times a second.\n\n\n\n\n\n","category":"function"},{"location":"tutorial_signals/#Signal-Processes","page":"Signal Processes","title":"Signal Processes","text":"","category":"section"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"Here we look at how to code up your own \"signal processes\". Note that we're not using the phrase \"signal processors\" but \"signal processes\" instead, to suggest processes that produce a sequence of sample values that vary over time while possibly updating internal state along the way. So each sample output is dependent on the previous state.","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"Some processes may be explicitly dependent on the time value, but we're in general interested in \"time invariant processes\" – i.e. where the evolution of a process does not depend on when in time it is played. While this seems like a restriction, it is a very meaningful restriction when it comes to music and sound processing where \"linear time invariant filters\" are a common way to alter the spectrum of sound.","category":"page"},{"location":"tutorial_signals/#The-delay-line","page":"Signal Processes","title":"The delay line","text":"","category":"section"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"To get an intro to how signals work in Synth.jl, it is instructive to look at how the delay line is designed. It is common in synthesizers to model a delay line with a fixed number of tap points which may vary over time. By contrast, in Synth.jl, the number of tap points of the delay line is not fixed and the tap points themselves can vary at audio rate. Here is how you'd use a delay line in Synth.jl.","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"s = #... some signal\nmaxdelay = 1.0 # in seconds\nd = delay(s, maxdelay)\ntapsig = oscil(0.25, 100.0)\ntap1 = tap(d, tapsig + 0.25)\ntap2 = tap(d, tapsig + 0.3)\nplay(tap1 * tap2, 2.0)","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"As you see, you create a delay, which is itself a pass-through signal which supports fanout. If you play the delayed signal directly, you won't notice any delay because that's how it is configured. To tap into the delay line, you create tap signals with a possibly time-varying tap point. These tap signals can then be used like ordinary signals in any further compositions.","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"This works because while the delay-line continuously updates based on the signal it is getting fed, the tap point's job is to simply look into the delay line and pick an interpolated value. In doing that, the tap points will trigger the delay line's processing function, but multiple tap points won't trigger it multiple times because the delay line supports intrinsic fanout.","category":"page"},{"location":"tutorial_signals/#Creating-your-own-signal-process","page":"Signal Processes","title":"Creating your own signal process","text":"","category":"section"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"To do this for your own signal, you need to do the following –","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"Create a concrete mutable subtype (say MySig) of Signal or SignalWithFanout.\nImplement done(::MySig, t, dt) :: Bool\nImplement value(::MySig, t, dt) :: Float32.\nMake an easy to use constructor function for your signal process.","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"The done method is expected to return true when the signal process is considered \"finished\". The done method is generally expected to be called once per audio frame (like 64 samples), but in some cases may be called more often. ","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"The value method is expected to compute the next sample value and return it. It is expected to return a valid value (typically 0.0f0 by convention) even if the signal is considered \"finished\" when the value method is called. i.e., the design of the implementation of the value method should be such that it is permissible for it to be called for a short while after the signal is considered \"finished\". The value method will in general update the state along the way as well.","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"As an example, here is a four-sample FIR filter.","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"using Synth : Signal\n\nmutable struct P4Filter{S <: Signal} <: Signal\n    sig :: S\n    a0 :: Float32\n    a1 :: Float32\n    a2 :: Float32\n    a3 :: Float32\n    x0 :: Float32\n    x1 :: Float32\n    x2 :: Float32\n    x3 :: Float32\nend\n\ndone(s:: P4Filter, t, dt) = done(s.sig, t, dt)\n\nfunction value(s::P4Filter{S}, t, dt) where {S <: Signal}\n    # Compute the next input sample value.\n    # If `s` happens to be a `SignalWithFanout`, then the\n    # main body of the value call will only get evaluated\n    # once for a given time `t`. Here, `dt` is generally\n    # 1/SR. So for the default sample rate, this will be 1/48000.\n    v = value(s.sig, t, dt)\n    \n    # Shift the sample memory by one sample.\n    s.x3 = s.x2\n    s.x2 = s.x1\n    s.x1 = s.x0\n    s.x0 = v\n\n    # Compute the output as a linear sum of the input sample values\n    # delayed by a few samples.\n    s.a0 * s.x0 + s.a1 * s.x1 + s.a2 * s.x2 + s.a3 * s.x3\nend\n\n# Make a convenient constructor. Note that any time-evolving state\n# in the structure should, if possible, not be exposed as constructor arguments.\n# Doing that will ensure that the signal process always starts in a known state.\n# In some situations, you might wish to expose the starting state, but they\n# are likely exceptions as usually they end up cluttering the interface.\nfunction p4filter(s :: S, a0 :: Real, a1 :: Real, a2 :: Real, a3 :: Real) where {S <: Signal}\n    MySig(s, Float32(a0), Float32(a1), Float32(a2), Float32(a3), 0.0f0, 0.0f0, 0.0f0, 0.0f0)\nend","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"With that much, you can already use your signal process on an equal footing with all the other operators in the package.","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"s = phasor(300)\nsf = p4filter(s, 0.2, 0.3, 0.3, 0.2) # Simple low pass\nplay(sf, 2.0)","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"If you want to support fanout intrinsically (as opposed to via fanout),  you should use SignalWithFanout as the abstract type and ensure that the computation done within value isn't repeated if asked repeatedly for the same time. You may assume that time increases monotonically. ","category":"page"},{"location":"tutorial_signals/#Performance-and-the-type-system","page":"Signal Processes","title":"Performance and the type system","text":"","category":"section"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"The way we defined P4Filter above, we introduced a signal type parameter that is made concrete at instantiation time. This means we aren't storing a dynamic signal value when constructing a P4Filter, but we know exactly what signal we're filtering using P4Filter. This is excellent for performance because the types are all know when compiling the value call on the P4Filter value and can be  optimized by Julia's just-ahead-of-time type specializing compiler.","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"Most signals defined in this package are designed similarly, so when you construct compound signals, you'll often find the types that get printed out for them to be very lengthy in printed form. i.e. The type of the signal carries all the information about the structure of the signal flow graph that is  necessary to optimize the computation of its values. ","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"Of course, for certain kinds of signals, this isn't possible. In particular, for the bus, to which signals that are not known ahead of time can be scheduled. In this case, the first call to value(::Bus,t,dt) will  do a dynamic dispatch (which is also reasonably fast in Julia), but often that dispatched function itself will have the entire call tree statically determined and will likely have a precompiled version available for use, thus speeding up the compilation.","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"In all this, it is possible that occasionally the compilation step takes a wee bit of time that may cause an audio stutter, but that has been somewhat rare in experience and can be mitigated through appropriate precompiled functions.","category":"page"},{"location":"tutorial_signals/","page":"Signal Processes","title":"Signal Processes","text":"In the design of the constructor function, we generally make the arguments be as general as possible and do the necessary type conversions to concrete types within the function when building up the struct. That way, the constructor functions end up being easy to use without being to strict about Float32  versus Float64 versus Int, for example.","category":"page"},{"location":"filters/#Filters","page":"Filters","title":"Filters","text":"","category":"section"},{"location":"filters/","page":"Filters","title":"Filters","text":"Linear time invariant first and second filters, with controllable filter parameters. Main ones are lpf, hpf and bpf second order filters. Also, delay and tap make a delay line that can be tapped at multiple points.","category":"page"},{"location":"filters/","page":"Filters","title":"Filters","text":"Synth.filter1\nSynth.filter2\nSynth.fir\nSynth.lpf\nSynth.bpf\nSynth.bpf0\nSynth.hpf\nSynth.delay\nSynth.tap\nSynth.maxdelay\nSynth.protect","category":"page"},{"location":"filters/#Synth.filter1","page":"Filters","title":"Synth.filter1","text":"filter1(s :: Signal, gain :: Signal)\n\nA first order filter where the gain factor that controls the bandwidth of the filter can be live controlled.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.filter2","page":"Filters","title":"Synth.filter2","text":"filter2(s :: Signal, f :: Signal, g :: Signal)\nfilter2(s :: Signal, f :: Signal, g :: Real)\nfilter2(s :: Signal, f :: Real, g :: Real)\n\nConstructs a second order filter where the frequency and the gamma can be controlled live.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.fir","page":"Filters","title":"Synth.fir","text":"fir(filt :: Vector{Float32}, sig :: Signal)\n\nConstructs a \"finite impulse response\" (FIR) filter with the given filt as the impulse response. Keep the filt argument short (to within about 1000 samples) in order for fir to be able to perform in realtime. The algorithm used is not suitable for very large FIR filter lengths ... which we'll perhaps add in the future.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.lpf","page":"Filters","title":"Synth.lpf","text":"lpf(sig :: Signal, freq, q; samplingrate=48000)\n\nStandard second order LPF with frequency and Q factor.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.bpf","page":"Filters","title":"Synth.bpf","text":"bpf(sig :: Signal, freq, q; samplingrate=48000)\n\nStandard second order bandpass filter with given centre frequency and Q factor. \n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.bpf0","page":"Filters","title":"Synth.bpf0","text":"bpf0(sig :: Signal, freq, q; samplingrate=48000)\n\nStandard second order bandpass filter with given centre frequency and Q factor. This variant of bpf gives constant 0dB peak gain instead of the peak gain being determined by Q.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.hpf","page":"Filters","title":"Synth.hpf","text":"hpf(sig :: Signal, freq, q; samplingrate=48000)\n\nStandard second order high pass filter with given cut off frequency and Q.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.delay","page":"Filters","title":"Synth.delay","text":"delay(sig :: Signal, maxdelay :: Real; samplingrate=48000)\n\nSets up a delay ring buffer through which the given signal is passed.  A delay is pretty much a pass through and is useful only in conjunction with tap. A delay can fanout on its own, which means you can make multiple tap points on the same delay based on time varying tap locations.\n\nsig is the signal that is delayed.\nmaxdelay is the maximum amount of delay possible.\nsamplingrate is the sampling rate in Hz. (This is needed to compute buffer size.)\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.tap","page":"Filters","title":"Synth.tap","text":"tap(d :: Delay, t :: Signal)\ntap(d :: Delay, t :: Real)\n\nYou can setup multiple time varying tap points on a delay line by calling tap multiple times and using it elsewhere. Since a delay is intrinsically fanout capable, this is possible without further ado.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.maxdelay","page":"Filters","title":"Synth.maxdelay","text":"maxdelay(sig :: Delay)\n\nReturns the maximum delay (in seconds) supported by the given delay unit.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.protect","page":"Filters","title":"Synth.protect","text":"protect(sig::Signal; cutoff::Real = 4000.0f0, q::Real = 10.0f0)\n\nDoes a simple LPF of the signal with a modest cut off frequency to prevent too many high frequencies from getting through and possibly causing aliasing effects.\n\n\n\n\n\n","category":"function"},{"location":"render/#Rendering","page":"Rendering","title":"Rendering","text":"","category":"section"},{"location":"render/","page":"Rendering","title":"Rendering","text":"Rendering a signal to samples, saving to a file and reading raw float32 from a file. For more support, use FileIO, WAV and such modules.","category":"page"},{"location":"render/","page":"Rendering","title":"Rendering","text":"render renders to a buffer in memory, Synth.write writes to a raw audio file and read_rawaudio reads in a raw float32 sample file into a buffer for playback.","category":"page"},{"location":"render/","page":"Rendering","title":"Rendering","text":"Synth.render\nSynth.write\nSynth.read_rawaudio","category":"page"},{"location":"render/#Synth.render","page":"Rendering","title":"Synth.render","text":"render(s :: Signal, dur_secs; samplingrate=48000, normalize=false, maxamp=0.5)\nrender(s :: Stereo{L,R}, dur_secs; samplingrate=48000) where {L <: Signal, R <: Signal}\n\nRenders the given signal to a flat Vector{Float32}, over the given dur_secs. If the signal terminates before the duration is up, the result is truncated accordingly. These functions return SampleBuf from SampledSignals package.\n\n\n\n\n\n","category":"function"},{"location":"render/#Synth.write","page":"Rendering","title":"Synth.write","text":"write(filename :: AbstractString, model::Signal, duration_secs :: AbstractFloat; samplingrate=48000, maxamp=0.5)\n\nRenders and writes raw Float32 values to the given file.\n\n\n\n\n\n","category":"function"},{"location":"render/#Synth.read_rawaudio","page":"Rendering","title":"Synth.read_rawaudio","text":"read_rawaudio(filename :: AbstractString)\n\nReads raw Float32 values from the given file into a Vector{Float32} that can then be used with sample or wavetable.\n\n\n\n\n\n","category":"function"},{"location":"faq/#FAQ","page":"FAQ","title":"FAQ","text":"","category":"section"},{"location":"faq/#How-to-make-a-signal-processor/generator-that-has-multiple-outputs?","page":"FAQ","title":"How to make a signal processor/generator that has multiple outputs?","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"The type Synth.Signal and its methods done and value imply that a signal is a single value at a point in time. So how do we represent multi-output signal processors using this approach?","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"If the outputs of a process are all to be computed synchronously in the same time step, then we can split the computation and access into two separate signals. While the main processing step computes all the outputs in its value implementation, it can output one chosen value, keeping the others as state in its structure.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"We can have secondary access signals which then pick out any of the many computed outputs so it can be composed with other parts of the signal flow graph.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"When using this approach, it is important that the main (multi-output) signal processing module supports fanout - so that a value call will do the computation only once for a given time t. ","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"For an example of this approach, see the implementation of the delay and tap signals. The delay line is modeled as a pass-through signal that keeps some history, and the tap is modeled as referencing a point within the history stored by an underlying delay line. This permits the creation of as many taps on a single delay line with their own individual controls as needed, even dynamically if necessary. In other systems, the number of tap points is usually specified up front for delay lines.","category":"page"},{"location":"faq/#How-to-time-limit-an-infinite-extent-signal-like-[oscil](@ref-\"Synth.oscil\")?","page":"FAQ","title":"How to time limit an infinite extent signal like oscil?","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Several signals like oscil are in principle infinitely extended in time. So when they're put to musical applications, various envelopes are applied to them to give the impression of musical \"events\" happening (such as \"a note\").","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"A plain way to limit the duration of a oscil is to use clip like this - clip(0.4, oscil(0.5f0, 330.0)). This will sharply delimit the waveform (whatever it happens to be and not just oscil) to a duration of (in our example) 0.4 seconds.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"A sharp delineation like clip is useful in some circumstances as a guard, but with specific notes. However, it can produce a \"click\" – i.e. a sudden change in signal level – at the start and end and such clicks are quite unmusical, to say the least. Therefore you usually apply an \"envelope\" like a raised cosine or an adsr to the amplitude like this – oscil(adsr(1.0f0, 0.4), 330.0). Now, the lifetime of the signal will be determined by the duration of the ADSR envelope since there are no other facets that determine the duration.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Most signals and signal transformers use their dependent signals to determine their duration and an \"in principle infinite\" signal like oscil is one of them. So you could clip the time extent of the frequency component as well, like this – oscil(0.5f0, clip(0.4, konst(330.0))). This will get rid of \"first order clicks\" in the output due to phase continuity, since the phase is determined by integrating the frequency. However, you'll hear a second order click since the rate at which the signal is changing suddenly changes and our ears pick that up.","category":"page"},{"location":"faq/#How-to-mix-two-signals-with-weights?","page":"FAQ","title":"How to mix two signals with weights?","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Mixing signals is a common operation needed and Synth makes it easy by supporting ordinary mathematical operations +, - and * on the Signal type entities. This means that if you have two signals a and b that you want 25%/75% mix of, you can do this – s = 0.25f0 * a + 0.75f0 * b.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"If you wish to, you can also use the mix and [Synth.modulate])(@ref) methods directly. They underpin the arithmetic operators which are mere convenience wrappers for them.","category":"page"},{"location":"faq/#How-do-I-play-a-stereo-composition?","page":"FAQ","title":"How do I play a stereo composition?","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"The Synth package primarily deals with monophonic signals since they're easy to compose. The composition properties of multi-channel signals are ambiguous at best. So this package makes stereo signals somewhat second class citizens, though there is some support. See stereo for info about how to construct and work with stereo signals.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"The approach taken in this package is that if there is an obvious way to compose stereo signals, it is usually supported. If there is some choice to be made, it is left to the user to effect that choice since sufficient lower level operations are available.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"stereo turns a pair of monophonic signals into a stereo signal.\nleft and right fetch the L and R components of a stereo signal. They don't bomb on mono signals and produce those as is for compatibility.\nOperators which support being applied on stereo signals will usually \"lift\" the stereo composition out and push the operation into the components of the signal. So it is somewhat unusual to have a stereo signal embedded deep into a composition tree that produces a mono signal in the end.\nrender and play support steroo signals directly.","category":"page"},{"location":"faq/#How-do-I-use-microphone-input?","page":"FAQ","title":"How do I use microphone input?","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"See [Synth.mic]. It is functional but still needs improvement to work reliably. You can choose an audio input by giving a pattern to match against the name of the device. The interface used is PortAudio so  you can get info about the various devices from its methods.","category":"page"},{"location":"utils/#Utilities","page":"Utilities","title":"Utilities","text":"","category":"section"},{"location":"utils/","page":"Utilities","title":"Utilities","text":"Misc functions needed in many applications. rescale scales an entire buffer, Synth.dBscale converts dB to amplitude, interp4 does 4-point interpolation, raisedcos is a masking waveform, midi2hz/hz2midi convert MIDI note numbers <-> Hz.","category":"page"},{"location":"utils/","page":"Utilities","title":"Utilities","text":"Synth.rescale\nSynth.dBscale\nSynth.interp4\nSynth.raisedcos\nSynth.midi2hz\nSynth.hz2midi\nSynth.easeinout\nSynth.curve\nSynth.Seg\nSynth.circular","category":"page"},{"location":"utils/#Synth.rescale","page":"Utilities","title":"Synth.rescale","text":"rescale(maxamp :: Real, samples :: AbstractArray) :: Vector{Float32}\n\nRescales the samples so that the maximum extent fits within the given maxamp (which must be positive). The renderer automatically rescales to avoid clamping.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.dBscale","page":"Utilities","title":"Synth.dBscale","text":"dBscale(::Real)\ndBscale(::Signal)\n\nConverts a dB value to a scaling factor\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.interp4","page":"Utilities","title":"Synth.interp4","text":"interp4(x, x1, x2, x3, x4)\n\nFour point interpolation.\n\nx is expected to be in the range [0,1].\n\nThis is a cubic function of x such that -\n\nf(-1) = x1\nf(0) = x2\nf(1) = x3\nf(2) = x4\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.raisedcos","page":"Utilities","title":"Synth.raisedcos","text":"raisedcos(x, overlap, scale=1.0f0)\n\nA \"raised cosine\" curve has a rising part that is shaped like cos(x-π/2)+1 and a symmetrically shaped falling part. If the overlap is 0.5, then there is no intervening portion between the rising and falling parts (x is in the range [0,1]). For overlap values less than 0.5, the portion between the rising and falling parts will be clamped to 1.0.\n\nFor example, raisedcos(x, 0.25) will give you a curve that will smoothly rise from 0.0 at x=0.0 to 1.0 at x=0.25, stay fixed at 1.0 until x = 0.75 and smoothly decrease to 0.0 at x=1.0.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.midi2hz","page":"Utilities","title":"Synth.midi2hz","text":"midi2hz(midi::Real)\nmidi2hz(::Signal)\n\nConverts a MIDI note number into a frequency using the equal tempered tuning.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.hz2midi","page":"Utilities","title":"Synth.hz2midi","text":"hz2midi(hz::Real)\nhz2midi(::Signal)\n\nConverts a frequency in Hz to its MIDI note number in the equal tempered tuning.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.easeinout","page":"Utilities","title":"Synth.easeinout","text":"easeinout(t::Float64)\n\nFor values of t in range [0.0,1.0], this curve rises smoothly from 0.0 and settles smoothly into 1.0. We're not usually interested in its values outside the [0.0,1.0] range.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.curve","page":"Utilities","title":"Synth.curve","text":"curve(segments :: Vector{Seg}; stop=false)\ncurve(ty::Type, v::AbstractVector{<:Tuple{Real,Real}}; stop = false)\ncurve(v::AbstractVector{<:Tuple{Real,Real}}; stop = false)\n\nMakes a piece-wise curve given a vector of segment specifications. Each Seg captures the start value, end value, duration of the segment, and the interpolation method to use in between.\n\nIf you pass true for stop, it means the curve will be done once all the segments are done. Otherwise the curve will yield the last value forever.\n\nThe \"tuple\" variants take a vector of (t,v) pairs and construct a curve out of it using a common interpolation mechanism. The Vector{Seg} is the most general since it can accommodate a combination of linear, exponential, etc., but these are convenient for use when a common interpolation type is required.\n\nCurves support map and basic arithmetic combinations with real numbers. See also stretch and concat\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.Seg","page":"Utilities","title":"Synth.Seg","text":"abstract type Seg end\n\nAbstract type represents a \"segment\" of a curve.\n\n\n\n\n\n","category":"type"},{"location":"utils/#Synth.circular","page":"Utilities","title":"Synth.circular","text":"circular(v::AbstractArray{T}) :: Circular{T,AbstractArray{T}}\n\nMakes a circular array that handles the modulo calculations.\n\n\n\n\n\n","category":"function"},{"location":"midi/#MIDI-output","page":"MIDI output","title":"MIDI output","text":"","category":"section"},{"location":"midi/","page":"MIDI output","title":"MIDI output","text":"Basic support for MIDI output are provided.","category":"page"},{"location":"midi/","page":"MIDI output","title":"MIDI output","text":"Synth.midioutput\nSynth.send\nSynth.noteon\nSynth.noteoff\nSynth.progchange\nSynth.ctrlchange\nSynth.keypressure\nSynth.aftertouch\nSynth.pitchbend\nSynth.midinop\nSynth.ismidinop","category":"page"},{"location":"midi/#Synth.midioutput","page":"MIDI output","title":"Synth.midioutput","text":"midioutput(name::AbstractString = \"\") :: MIDIOutput\n\nIdentifies a MIDI output device with the given name as a substring and opens a stream to write data to it. You can call Base.close on the resultant MIDIOutput to close the stream.\n\nThrows MIDIOutputDeviceNotFoundError if such a device does not exist.\n\n\n\n\n\n","category":"function"},{"location":"midi/#Synth.send","page":"MIDI output","title":"Synth.send","text":"send(dev::MIDIOutput, msg::MIDIMsg)\n\nSends the MIDIMsg to the device immediately.\n\n\n\n\n\n","category":"function"},{"location":"midi/#Synth.noteon","page":"MIDI output","title":"Synth.noteon","text":"noteon(chan::Int, note::Int, vel::Int) :: MIDIMsg\nnoteon(chan::Int, note::Int, vel::AbstractFloat) :: MIDIMsg\n\nConstructs a NoteOn message. The AbstractFloat version will take a velocity value in the range 0.0 to 1.0 and convert it to the MIDI range. Note that for sustained instruments like violin, you'll have to also send a noteoff at an appropriate time or else the voices will accumulate and result in your system being unable to keep up.\n\nSee also noteoff\n\n\n\n\n\n","category":"function"},{"location":"midi/#Synth.noteoff","page":"MIDI output","title":"Synth.noteoff","text":"noteoff(chan::Int, note::Int, vel::Int = 0) :: MIDIMsg\n\nConstructs a NoteOff message. See also noteon\n\n\n\n\n\n","category":"function"},{"location":"midi/#Synth.progchange","page":"MIDI output","title":"Synth.progchange","text":"progchange(chan::Int, pgm::Int)\n\nSend a \"program change\" for the given channel. See General MIDI if you're using a GM compatible synthesizer.\n\n\n\n\n\n","category":"function"},{"location":"midi/#Synth.ctrlchange","page":"MIDI output","title":"Synth.ctrlchange","text":"ctrlchange(chan::Int, control::Int, val::Int) :: MIDIMsg\nctrlchange(chan::Int, control::Int, val::AbstractFloat) :: MIDIMsg\n\nChanges the value associated with the given control number. The AbstractFloat value is in the range 0.0-1.0 and will be rescaled to the MIDI range 0-127.\n\n\n\n\n\n","category":"function"},{"location":"midi/#Synth.keypressure","page":"MIDI output","title":"Synth.keypressure","text":"keypressure(chan::Int, note::Int, pressure::Int) :: MIDIMsg\nkeypressure(chan::Int, note::Int, pressure::AbstractFloat) :: MIDIMsg\n\nThe key pressure control after a note is turned on, before the note has conceptually ended. See also aftertouch. The AbstractFloat version will rescale the pressure value from the 0.0-1.0 range to the MIDI range of 0-127.\n\n\n\n\n\n","category":"function"},{"location":"midi/#Synth.aftertouch","page":"MIDI output","title":"Synth.aftertouch","text":"aftertouch(chan::Int, note::Int, pressure::Int) :: MIDIMsg\naftertouch(chan::Int, note::Int, pressure::AbstractFloat) :: MIDIMsg\n\nThe key pressure control after a note has conceptually ended. See also aftertouch. The AbstractFloat version will rescale the pressure value from the 0.0-1.0 range to the MIDI range of 0-127.\n\n\n\n\n\n","category":"function"},{"location":"midi/#Synth.pitchbend","page":"MIDI output","title":"Synth.pitchbend","text":"pitchbend(chan::Int, signedPB::Int)\npitchbend(chan::Int, signedPB::AbstractFloat)\n\nSends a 14-bit pitch bend value on the given channel. The sensitivity of this value will depend on the instrument. The AbstractFloat version will rescale (i.e. multiply) by 127 to construct a signed 14-bit value. So values < 1.0 will correspond to microtonal pitch bends.\n\n\n\n\n\n","category":"function"},{"location":"midi/#Synth.midinop","page":"MIDI output","title":"Synth.midinop","text":"midinop :: MIDIMsg\n\nA constant MIDIMsg that represents a \"no-op\" or \"nothing to be sent out\".\n\n\n\n\n\n","category":"constant"},{"location":"midi/#Synth.ismidinop","page":"MIDI output","title":"Synth.ismidinop","text":"ismidinop(m::MIDIMsg) :: Bool\n\nReturns true if the given message is a midinop.\n\n\n\n\n\n","category":"function"},{"location":"design/#Design","page":"Design","title":"Design","text":"","category":"section"},{"location":"design/","page":"Design","title":"Design","text":"In Synth, you describe audio signals using signal constructors and combinators and finally pass them on to a renderer - either one that renders to a file or one that plays it back in real time.","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"A \"signal\" (represented by the abstract type Synth.Signal) therefore identifies the computation that produces the samples with the mathematical notion of a time-varying value that's sampled at a regular rate, known as the \"sampling rate\". ","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"note: Sampling rate\nThis is the number of audio samples per second. CDs uses 44.1KHz as the sampling rate. This package chooses 48KHz as the sampling rate by default wherever necessary.","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"A \"signal\" in this package is defined by its support for two methods –","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"done(s :: S, t, dt) :: Bool where {S <: Signal}\nvalue(S :: S, t, dt) :: Float32 where {S <: Signal}","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"The done method indicates whether a signal is finished at a given time or not. It is expected to obey the following constraints –","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"done(s, t, dt) == true implies done(s, t', dt) == true for all t  t.\ndone(s, t, dt) == false implies done(s, t', dt) == false for all t  t.","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"The value method computes the value of the signal s at the given time t. It too has a constraint, albeit a soft one – value(s, t, dt) == 0.0f0 for all t for which done(s, t, dt) == true. In some cases, value may choose to return a constant other than 0.0f0, but the idea is that the value calculation must not assume that only values of t for which done will produce false will be supplied. This soft constraint is so that done does not need to be called per sample by any render. It only needs to be called per \"frame\" - which is like 64 samples or 128 samples depending on the buffer length.","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"Additionally, value is expected to be called with a monotonic t argument in time steps of dt – i.e. t can either be the same as that of the previous call, or can advance by the given dt. Most signals do not need to account for repeated calls with same t since that can be handled by wrapping a concrete type as an fanout. ","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"The value method on a signal computes a single sample value. Having a function call to compute a single sample sounds like a significant overhead, but the way the types are organized and how Julia does a deep type specializing optimizing compilation pass on the entire call graph of a function implies that most of these calls get optimized away. When you compose signals and look at their type signature, you'll see how all the composition information is reflected in the resultant signal type and this is the information that's needed to optimize the value call on the composite signal. The value method implementation on a type also provides a boundary at which to perform such optimizations. Mostly, you as a user don't need to think about these optimizations.","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"note: Compilation cost\nWhat this package relies on is Julia's type specializing just-ahead-of-time compiler. This compilation pass can take a noticeable amount of time for modest sized functions. This means that a freshly composed signal that Julia has not seen at all will likely cause a stutter the first time it is run. For this reason, it is good to mark all the combinations under a test function that gets called once before you do any realtime performance. This compilation delay will not make a difference if you're just rendering to a file though.","category":"page"},{"location":"env/#Envelopes","page":"Envelopes","title":"Envelopes","text":"","category":"section"},{"location":"env/","page":"Envelopes","title":"Envelopes","text":"Shaping the amplitude contour of a signal is a common need and the envelope functions are there to help you with that. Of these, perhaps the most useful is adsr which can be live controlled in  addition to being of a pre-determined shape and duration.","category":"page"},{"location":"env/","page":"Envelopes","title":"Envelopes","text":"Synth.line\nSynth.expon\nSynth.adsr\nSynth.decay\nSynth.follow\nSynth.Gen","category":"page"},{"location":"env/#Synth.line","page":"Envelopes","title":"Synth.line","text":"line(v1 :: Real, duration_secs :: Real, v2 :: Real)\n\nMakes a signal that produces v1 for t < 0.0 and v2 for t > duration_secs. In between the two times, it produces a linearly varying value between v1 and v2. This signal is infinite in extent. Use clip to limit its extent.\n\n\n\n\n\n","category":"function"},{"location":"env/#Synth.expon","page":"Envelopes","title":"Synth.expon","text":"expon(v1 :: Real, duration_secs :: Real, v2 :: Real)\n\nSimilar to line, but does exponential interpolation from v1 to v2 over duration_secs. Note that both values must be > 0.0 for this to be valid. The resultant signal is infinite in extent. Use clip to limit its extent.\n\n\n\n\n\n","category":"function"},{"location":"env/#Synth.adsr","page":"Envelopes","title":"Synth.adsr","text":"adsr(suslevel :: Real, sus_secs :: Real;\n     attack_factor = 2.0, attack_secs = 0.002,\n     decay_secs = 0.01, release_secs = 0.2,\n     release_factor = 4.0, samplingrate=48000)\n\nMakes an \"attack-decay-sustain-release\" envelope. The decay and release phases are treated as exponential and the others stay linear. The arguments are arranged such that mostly you specify the suslevel and sus_secs, which control the amplitude and duration of a note controlled by the ADSR. The rest are given defaults that you can change if needed.\n\nsuslevel is the sustain level\nsus_secs is the duration of the sustain portion\nattack_factor determines the peak of the attack and multiplies the sustain level.\nattack_secs is the duration of the linear attack portion\ndecay_secs is the duration of the exponential decay portion after the attack.\nrelease_secs is the \"half life\" of the release portion of the envelope.\nrelease_factor is the number of \"releasesecs\" it takes to drop the amplitude to 0. When the amplitude drops below 1/32767, the signal will stop. If we let the decay happen at a steady logarithmic pace of a factor of 2 every `releasesecs, it can take a full 3 seconds for it to stop even whenreleasesecs == 0.2. This can cause computational cost to go up because voices will remain alive for longer without actually being audible. So we accelerate the drop instead of using a steady logarithmic drop velocity, so that the signal will end within aboutreleasefactor * releasesecsafter release phase begins. Thisreleasefactordefaults to 4. This \"acceleration\" tends to 0 as thereleasefactorbecomes larger. So if you strictly want thereleasesecsto be the \"half life\" of the signal, set this factor to be 15.0. Setting it to any value above 15.0 will cause the signal to linger on and decay at a slower rate than indicated byrelease_secs`.\n\n\n\n\n\n","category":"function"},{"location":"env/#Synth.decay","page":"Envelopes","title":"Synth.decay","text":"decay(rate :: Signal)\n\nProduces a decaying exponential signal with a \"half life\" determined by 1/rate. It starts with 1.0. The signal includes a short attack at the start to prevent glitchy sounds.\n\n\n\n\n\n","category":"function"},{"location":"env/#Synth.follow","page":"Envelopes","title":"Synth.follow","text":"follow(s :: Signal, rate :: Signal)\nfollow(s :: Signal, rate :: Real)\n\nFollows a signal on the rise and decays on the fall. This means if the input signal is an impulse, then  you'll get a series of exponential decays on each of the impulses.\n\n\n\n\n\n","category":"function"},{"location":"env/#Synth.Gen","page":"Envelopes","title":"Synth.Gen","text":"abstract type Gen end\n\nA \"Gen\" is a process for producing signals. The proc(::Gen,::AbstractBus,t,rt) which returns Tuple{Float64,Gen} needs to be defined for a gen to be usable by the Bus.\n\nThe Gen returned by the proc call semantically replaces the gen that produced it. That way, we get recursive generation.\n\n\n\n\n\n","category":"type"},{"location":"music/#For-music","page":"For music","title":"For music","text":"","category":"section"},{"location":"music/","page":"For music","title":"For music","text":"A \"Gen\" has a method to implement which has the signature - ","category":"page"},{"location":"music/","page":"For music","title":"For music","text":"proc(::Gen, ::Bus, t::Float64) -> Tuple{Float64,Gen}","category":"page"},{"location":"music/","page":"For music","title":"For music","text":"The proc method is expected to schedule any signals to the bus using sched(::Bus,t,::Signal) and return info about the next gen to trigger later. The t argument to proc is \"clock time\" and not real time - i.e. it is determined by the clock which the bus runs.","category":"page"},{"location":"music/","page":"For music","title":"For music","text":"Synth.Gen\nSynth.seq\nSynth.track\nSynth.durn\nSynth.chord\nSynth.par\nSynth.loop\nSynth.dyn\nSynth.rec\nSynth.ping\nSynth.tone\nSynth.ch\nSynth.snippet","category":"page"},{"location":"music/#Synth.seq","page":"For music","title":"Synth.seq","text":"seq(ga :: GA, gb :: GB) :: Gen where {GA <: Gen, GB <: Gen}\n\nSequences the given two gens to occur one after the other. When the first gen ga results in a Cont, it will switch to gb and after that will continue onwards.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.track","page":"For music","title":"Synth.track","text":"track(gs :: AbstractVector) :: Gen\n\nA \"track\" is a heterogeneous sequence of Gens. When each gen finishes, its genproc call will produce a Cont which indicates it is time to switch to the next Gen in the track. This is like a generalization of seq except that seq has types known at construction time.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.durn","page":"For music","title":"Synth.durn","text":"durn(d :: Real, gen :: Gen) :: Gen\n\nForces the duration of the given gen to be the given d, even if it was something else. Possibly useful with chord.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.chord","page":"For music","title":"Synth.chord","text":"chord(gens :: AbstractVector) :: Gen\n\nA Gen which runs all the given heterogeneous gens in lock step. The duration of the chord is given by the maximum of the durations of all the gens every time they run. Whenever a gen produces a Cont or Stop, it is taken out of the set of gens and the other continue on.\n\nBroadly, chord is useful when all the gens have the same duration - very much like a chord in music. If you're thinking of whether you should use this to start off multiple musical processes in parallel with each determining its own duration, you probably want par.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.par","page":"For music","title":"Synth.par","text":"par(gens :: AbstractVector) :: Par\n\nFor parallel composition of gens given as a vector. The Par itself has effectively zero duration and when sequenced as part of a track will result in the following gen being immediately processed without delay. The individual gens part of each of the \"threads\" will continue to be processed by the bus over time until they finish.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.loop","page":"For music","title":"Synth.loop","text":"loop(n :: Int, g :: Gen) :: Gen\n\nWill loop the given gen n times before ending.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.dyn","page":"For music","title":"Synth.dyn","text":"dyn(fn :: Function, n :: Int, i :: Int) :: Gen\n\nA \"dyn\" gen calls the function with each i to determine the gen that should be performed. The function will be called with two arguments i and n where i will range from 1 to n.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.rec","page":"For music","title":"Synth.rec","text":"rec(fn :: Function, c :: C, s :: S) :: Gen where {C,S}\n\nConstructs a recursive process using the given function. The function takes the current state and is expected to return a tuple of a Gen and the next state. If the returned gen is Cont, then the gen is considered finished and will move on to the next gen in whatever context it was invoked.\n\nIterating an octave\n\nFor example, if you want a gen which iterates through the pitches of an octave you can do it this way (though you can accomplish it using track as well).\n\nfunction octave(p :: Real, i :: Int)\n    if i <= 12\n        (tone(p + i, 0.25), i+1)\n    else\n        (Cont(), i+1)\n    end\nend\nb = bus()\nsched(b, rec(octave, 60, 0::Int))\nplay(b, 4.0)\n\nrec is therefore a general mechanism to implement stateful recursive time evolution at a level higher than signals. Note that the function called by rec can itself return another recursive process as a part of its evolution.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.ping","page":"For music","title":"Synth.ping","text":"ping(pitch :: Real, dur :: Real, vel :: Real = 0.5f0, decay :: Real = dur) :: Gen\nping(pitch :: AbstractVector{R}, dur :: Real, vel :: Real = 0.5f0, decay :: Real = dur) :: Gen where {R <: Real}\nping(pitch :: AbstractVector{R}, dur :: AbstractVector{RD}, vel :: Real = 0.5f0, decay :: Real = dur) :: Gen where {R <: Real, RD <: Real}\nping(pch :: PitchChord, dur :: Real, vel :: Real = 0.5f0, decay :: Real = dur) :: Gen\n\nA \"ping\" is a simple decaying sine tone for illustrating how to create a Gen. If you use the array versions, they're made into corresponding tracks for ease of use. So ping([60,67,72], 0.5) would be a three-note track. If the duration is also an array, it will be cycled through for each of the pitch values. So the number of pings is determined only by the number of pitches given.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.tone","page":"For music","title":"Synth.tone","text":"tone(pitch :: Real, dur :: Real, vel :: Real = 0.5f0; release_secs :: Real = 0.05) :: Gen\ntone(pitch :: AbstractVector{R}, dur :: Real, vel :: Real = 0.5f0; release_secs :: Real = 0.05) :: Gen where {R <: Real}\ntone(pitch :: AbstractVector{R}, dur :: AbstractVector{RD}, vel :: Real = 0.5f0; release_secs :: Real = 0.05) :: Gen where {R <: Real, RD <: Real}\ntone(pch :: PitchChord, dur :: Real, vel :: Real = 0.5f0, release_secs :: Real = 0.05) :: Gen\n\ntone is related to ping in that it will sustain a tone for the given duration as opposed to ping which will immediately start releasing the tone. In other words, a ping is a note with zero duration. However, the note is configured with a default short release time where the default release of a ping is determined by its duration.\n\nNote that you can force the duration of a gen to be whatever you want using durn.\n\n\n\n\n\ntone(wt :: WaveTone, pitch, dur, vel = 0.5f0; release_secs = 0.05)\n\nWith this, you can take an existing configured wavetable tone and assign a different pitch/dur/vel characteristic to it.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.ch","page":"For music","title":"Synth.ch","text":"ch(pitches :: AbstractVector{R}) :: PitchChord where {R <: Real}\n\nRepresents a set of chorded pitch values. Usable with ping.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.snippet","page":"For music","title":"Synth.snippet","text":"snippet(filename::AbstractString, selstart :: Float64 = 0.0, selend :: Float64 = Inf) :: Gen\n\nA Gen that plays a fragment of the given audio file. It uses sample under the hood and therefore relies on its caching mechanism for speedy schedule of sample fragment playback.\n\nNote that both snippet and sample do not support resampling or playing back to clocks that vary their speeds from real time. So you need to be careful with duration computation. For example, when scheduling on to a bus running at a tempo of 120bpm, you'll need to double your durations using durn in order to synchronize with the end of the snippet. Otherwise, the next Gen will start playing half way through the snippet.\n\n\n\n\n\n","category":"function"},{"location":"music/#MIDI-specific","page":"For music","title":"MIDI specific","text":"","category":"section"},{"location":"music/","page":"For music","title":"For music","text":"Note that MIDI sequencing is unfinished. Particularly it requires accurate scheduling.","category":"page"},{"location":"music/","page":"For music","title":"For music","text":"Synth.midimsg\nSynth.midinote\nSynth.miditrigger\nSynth.midiseq","category":"page"},{"location":"music/#Synth.midimsg","page":"For music","title":"Synth.midimsg","text":"midimsg(dev::MIDIOutput, msg::MIDIMsg)\n\nWraps sending an instantaneous MIDI short message to the given output device.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.midinote","page":"For music","title":"Synth.midinote","text":"midinote(dev::MIDIOutput, chan::Int, note::Int, vel::Real, dur::Real, logicaldur::Real = dur)\n\nProduces a MIDI note of given duration. The note off will be scheduled appropriately and the note will be set to last the given duration. The logicaldur parameter gives the logical duration of the note which is taken to be the same as the time interval between noteon and noteoff by default.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.miditrigger","page":"For music","title":"Synth.miditrigger","text":"miditrigger(dev::MIDIOutput, chan::Int, note::Int, vel::Real, logicaldur::Real)\n\nA triggered MIDI message only has a noteon - such as for a drum hit, which does not require a note off since the drum voices have a natural  cut off point.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.midiseq","page":"For music","title":"Synth.midiseq","text":"midiseq(seq::AbstractVector{Tuple{Float64, MIDIMsg}}) :: MidiSeq\n\nA simple sequence of MIDI messages to be sent at given times relative to start of the Gen. This could technically be constructed as a track as well, but permits a more general sequence of short messages to be sent.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Realtime-playback","page":"Realtime playback","title":"Realtime playback","text":"","category":"section"},{"location":"rt/","page":"Realtime playback","title":"Realtime playback","text":"Methods that provide support for realtime playback as opposed to static file based rendering. The commonly used method is play. To work at a higher level with sample accurate scheduling of sound events, see Synth.Gen and the associated gens track, loop and the example ping. For interactivity, see control (for UI to signal) and probe (for signal to UI).","category":"page"},{"location":"rt/","page":"Realtime playback","title":"Realtime playback","text":"Synth.startaudio\nSynth.play\nSynth.mic\nSynth.control\nSynth.stop\nSynth.probe\nSynth.waveprobe\nSynth.level\nSynth.bus\nSynth.sched\nSynth.now\nSynth.after","category":"page"},{"location":"rt/#Synth.startaudio","page":"Realtime playback","title":"Synth.startaudio","text":"startaudio(callback)\n\ncallback is a function that will be called like callback(sample_rate, readqueue, writequeue). sample_rate indicates the output sampling rate. readqueue and writequeue are Channels that accept either an audio buffer as a Vector{Float32} or Val(:done) to indicate completion of the audio process. The callback is expected to take! a buffer from the readqueue, fill it up and submit it to the writequeue using put!.\n\nWhen the audio generation is done, callback should put!(writequeue, Val(:done)) and break out of its generation loop and return.\n\nIt returns a function that can be called (without any arguments) to stop the audio processing thread. Make sure to start julia with a sufficient number of threads for this to work.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.play","page":"Realtime playback","title":"Synth.play","text":"play(signal::Signal, duration_secs=Inf; blocksize=64)\nplay(soundfile::AbstractString)\n\nPlays the given signal on the default audio output in realtime for the given duration or till the signal ends, whichever happens earlier. Be careful about the signal level since in this case the signal can't be globally normalized.\n\nThe version that takes a string is a short hand for loading the file and playing it. The file is cached in memory, so it won't load it again if you call it again.\n\nReturns a stop function (like with startaudio which when called with no arguments will stop playback.\n\n\n\n\n\nplay(m::Gen, duration_secs = Inf)\n\nTo play a Gen, it needs to be scheduled on a bus. This overloaded version of play automatically does that for you. Similar to the overload for playing a signal, it returns a stop function that can be called to terminate playback at any time.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.mic","page":"Realtime playback","title":"Synth.mic","text":"mic(dev :: AbstractString = \"mic\"; blocksize :: Int = 128, samplingrate :: Float64 = 48000.0)\n\nOpens input from the default mono mic source. You shouldn't need to fiddle with the blocksize and samplingrate, but they're available for configuration.\n\nA Mic supports intrinsic fanout and therefore you shouldn't need to create multiple mic instances on the same audio interface.\n\nTodo: At some point, support selecting named audio sources and also stereo sources.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.control","page":"Realtime playback","title":"Synth.control","text":"control(chan :: Channel{Float32}, dezipper_interval = 0.04; initial = 0.0f0, samplingrate=48000) :: Control\ncontrol(dezipper_interval = 0.04; initial = 0.0f0, samplingrate = 48000) :: Control\n\nA \"control\" is a signal that is driven by values received on a given or created channel. The control will dezipper the value using a first order LPF and send it out as its value. The intention is to be able to bind a UI element that produces a numerical value as a signal that can be patched into the graph.\n\nIf c is a Control struct, you can set the value of the control using c[] = 0.5f0.\n\nClose the channel to mark the control signal as \"done\".\n\nnote: Channels and memory\nA control signal uses a channel to receive its values. This raises a question about the amount of memory that'll be consumed by using what looks like a system resource. Julia's channels cost about 416 bytes each, meaning a 1000 channels, which would be a pretty complex scenario to put it mildly, will be well under 1MB. Even if you have 1000 voices with 10 channels controlling each voice, the memory won't be significant (under 5MB) by 2025 standards.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.stop","page":"Realtime playback","title":"Synth.stop","text":"stop(c :: Control)\n\nStops the control signal. From the renderer's perspective, the control signal will switch to the \"done\" state. The control channel will close, causing any further put! calls to raise an exception. If you control the sustain of an adsr using a control signal, then stopping the control will basically end the ADSR envelope by switching it into \"release\" phase.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.probe","page":"Realtime playback","title":"Synth.probe","text":"probe(s :: Signal, interval :: Float64 = 0.04; samplingrate = 48000) :: Probe\n\nA probe is a \"pass through\" signal transformer which periodically reports a reading of the signal to a channel. The channel may either be given or a new one can be created by the second variant. Since it is a pass-through, you can insert a probe at any signal point. A probe low-pass-filters the signal before sending it out the channel, so it won't be useful for signals that vary very fast. The default value has it sampling the signal every 40ms.\n\nThe channel can then be connected to a UI display widget that shows values as they come in on the channel.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.waveprobe","page":"Realtime playback","title":"Synth.waveprobe","text":"waveprobe(s :: Signal, duration :: Float64 = 0.25, interval :: Float64 = 0.04; samplingrate = 48000) :: Probe\n\nA waveprobe, like probe is a \"pass through\" signal transformer which periodically reports a reading of the signal to an Observable. Since it is a pass-through, you can insert a probe at any signal point. The default value has it sampling the signal every 40ms.\n\nconnectui can be used to connect a Probe{TimedSamples} to a WaveProbe.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.level","page":"Realtime playback","title":"Synth.level","text":"level(s::Signal; interval=0.015, refmin=1/(32767*32767), samplingrate=48000)\n\nComputes the smoothed dB level of a signal. The range is from 0 to about 90dB. \n\nrefmin is the tiniest sliver of sound intensity that can be registered. The default is set to a value appropriate for 16-bit sampled sound.\ninterval is the smoothing interval - i.e. the time constant of the first order filter that's applied on the square of the signal.\n\nrefmin determines the range since it is the floor of the signal that is 0dB. For the default value, the max ends up around 20log_10(32767) approx 90309textdB. A factor of two change in amplitude is a change in level of around 6.021 dB.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.bus","page":"Realtime playback","title":"Synth.bus","text":"bus(clk :: Signal) :: Bus\n\nCreates a \"bus\" which is itself a signal that can be composed with other signals and processors. The bus runs on its own  clock and sending Tuple{Float64,Signal} values on the .gchan property will trigger those signals at the given times according to the clock. The scheduling is sample accurate.\n\nA \"bus\" supports fanout.\n\n\n\n\n\nbus(tempo_bpm::Real)\n\nSimpler constructor for a fixed tempo bus.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.sched","page":"Realtime playback","title":"Synth.sched","text":"sched(sch :: Bus{Clk}, t::Real, s::Signal) where {Clk <: Signal}\nsched(sch::Bus{Clk}, s::Signal) where {Clk<:Signal}\nsched(sch::Bus{Clk}, t::Real, g::Gen) where {Clk<:Signal}\nsched(sch::Bus{Clk}, g::Gen) where {Clk<:Signal}\n\nSchedules a signal to start at time t according to the clock of the given bus. In the third variant without a t, the scheduling happens at an ill-specified \"now\" - which basically means \"asap\". \n\nNote: When scheduling signals and gens within a proc() call, a maximum of 16 is supported. You usually won't need so many since any co-scheduled gens and signals usually have a temporal relationship that is better captured using available composition operators.\n\n\n\n\n\nsched(dev::MIDIOutput, t::Real, msg::MIDIMsg)\nsched(t::Real, msg::MIDIMsg)\nsched(dev::MIDIOutput, msg::MIDIMsg)\nsched(msg::MIDIMsg)\n\nThe first two schedule a MIDI message to be sent at the designated time. The last two will send it out immediately. If the MIDI output device is omitted, then the current midi output device active will be used.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.now","page":"Realtime playback","title":"Synth.now","text":"now(s::Bus{<:Signal})::Float64\nnow(s::Bus{<:Signal}, b::Type{<:Integer})::Float64\nnow(s::Bus{<:Signal}, b::Rational)::Float64\nnow(s::Bus{<:Signal}, b::Integer)::Float64\n\nReturns the bus' \"current time\". If a beat is passed or asked for, the time is quantized to beats according to the clock's tempo.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.after","page":"Realtime playback","title":"Synth.after","text":"after(delay_secs :: Float64, s :: Signal)\n\nPostpones the signal by the given delaysecs. Note that this is not the same as a delay line where there is memory allocated to store some of the samples. The signal is not touched until `delaysecs` has passed, and the time value that the signal ends up seeing also does not span the period up to the delay.\n\n\n\n\n\n","category":"function"},{"location":"tutorial_synth/#Sampling-synthesis","page":"Sampling synthesis","title":"Sampling synthesis","text":"","category":"section"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"The \"Basic tutorial\" showed how to construct and use simple oscillators and control them using other signals. Along similar lines, we can also use audio samples - either short waveforms intended for looping through or full samples intended to be played even as single shot.","category":"page"},{"location":"tutorial_synth/#Playing-a-sample","page":"Sampling synthesis","title":"Playing a sample","text":"","category":"section"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"sample provides means to take a pre-recorded snippet and play it back end to end, with optional looping builtin. You can create a sample player either from a raw Vector{Float32} or load it from a file in a format supported by FileIO/LibSndFile.","category":"page"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"> s = sample(\"speech.wav\")\n# By default, the sample is not configured to loop. See `looping`\n# and `loopto` arguments for how to set that up.\n> play(s)","category":"page"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"Note: For now, only 48000Hz is supported as the sampling rate. No sampling rate conversion will be done on files and therefore the files must all be at 48KHz. Furthermore, sample will only load one channel from the file if it is stereo. Full stereo support and sampling rate conversion may be added in the future, but for now these limits apply.","category":"page"},{"location":"tutorial_synth/#Looping-a-wave-table","page":"Sampling synthesis","title":"Looping a wave table","text":"","category":"section"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"While sample plays back a recorded piece of sound, what we often want to do is to take a periodic waveform recorded off a real instrument and loop it with various time stretches  to mimic playing the instrument. This is referred to as \"wavetable synthesis\".","category":"page"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"You can make such a wavetable sound with parametric control over the amplitude and phase using wavetable. A case of basic playback of a loop with a \"sirening\" of the frequency is shown below -","category":"page"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"> w = wavetable(sample(\"waveform.wav\"), 0.25f0, phasor(440 + oscil(50, 10)))\n> play(w, 2.0)","category":"page"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"The wavetable player supports 4-point interpolation and therefore  even short tables can be stretched out a fair bit.","category":"page"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"Otherwise, a wavetable player is an ordinary stateful Signal and can be used in the same way as any other \"signal process\".","category":"page"},{"location":"tutorial_synth/#Registered-sounds","page":"Sampling synthesis","title":"Registered sounds","text":"","category":"section"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"It is often convenient to load a bunch of sounds and refer to them by name. The register! method can store wavetables and samples associated with a symbol and the symbol can then be used with wavetable and sample to retrieve them.","category":"page"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"> register!(:hh, sample(\"hihat.wav\"))\n> play(sample(:hh))\n> register!(:horn, sample(\"horn_loop.wav\"))\n> play(wavetable(:horn, 0.25, 440), 2.0)","category":"page"},{"location":"tutorial_synth/","page":"Sampling synthesis","title":"Sampling synthesis","text":"Note that when given a number as the third argument, wavetable will treat it as a frequency and not as a phase, because it doesn't make sense to fix the phase of a wavetable when playing it. If you want to vary the frequency over time, use a phasor and vary its argument like shown in the example above.","category":"page"},{"location":"fx/#Effects","page":"Effects","title":"Effects","text":"","category":"section"},{"location":"fx/","page":"Effects","title":"Effects","text":"Synth.compress","category":"page"},{"location":"fx/#Synth.compress","page":"Effects","title":"Synth.compress","text":"compress(s :: Signal, k :: Signal; τ :: AbstractFloat = 0.03f0, samplingrate=48000)\n\nCompresses the signal using a dynamic compression algorithm.\n\ns is the signal to compress\nk is the amount of compression to apply. Must be positive. If k == 1, then  the compression applied can go up to a factor of half. The more the k, the more the compression that's applied for louder sounds.\nτ is the time constant (half life) over which the signal strength is measured to determine the adaptive compression.\n\n\n\n\n\n","category":"function"},{"location":"tutorial_basic/#Basic-tutorial","page":"Basic tutorial","title":"Basic tutorial","text":"","category":"section"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"The \"Getting Started\" section covered playing and rendering audio by constructing \"signal processes\" modelled as the abstract type Synth.Signal. In this basic tutorial, we'll construct various such signals and explore the operators available to combine them.","category":"page"},{"location":"tutorial_basic/#Phasors-and-sines","page":"Basic tutorial","title":"Phasors and sines","text":"","category":"section"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"Oscillators form the basic signals for composition purposes. The phasor and oscil are two of the most basic oscillators available for composition. The code below assumes using Synth.","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"Play a 440Hz tone at 0.25 amplitude for 2.0 seconds.\n> play(oscil(0.25, 440.0), 2.0)\nPlay a middle C note at 0.25 amplitude for 2.0 seconds.\n> play(oscil(0.25, midi2hz(60)), 2.0)\nHere, midi2hz is used to convert a MIDI note number to a Hz frequency value. This function also supports constructing signal processes and therefore you can add a vibrato like using midi2hz(60 + oscil(0.3, 5.0)) for example.\nPlay a harsh sawtooth wave.\n> play(0.25 * phasor(440.0), 2.0)\nThe phasor goes from 0.0 to 1.0 at the given frequency and loops around. It therefore has a discontinuous jump from 1.0 to 0.0.\nPlay a sawtooth, square or triangular wave.\n> play(0.25 * tri(440.0), 2.0)\n> play(0.25 * saw(440.0), 2.0)\n> play(0.25 * sq(440.0), 2.0)\nThese are \"softened\" version where the sharpness of these waveforms is mitigated using a large cut off low-pass-filter. (See protect).\nYou can combine these waveforms using common addition and modulation operations.\n> play(0.2 * tri(330.0) + 0.4 * tri(440.0) + oscil(0.2, 660.0), 2.0)\nYes the multipliers can themselves be signals, so the following works too.\n> play(oscil(1.0, 10.0) * oscil(0.25, 440.0), 2.0)","category":"page"},{"location":"tutorial_basic/#Filters","page":"Basic tutorial","title":"Filters","text":"","category":"section"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"Many types of linear time invariant filters are available, including first order and second order, biquad and FIR filters. A \"filter\" attenuates or enhances a set of frequencies present in the spectrum of a signal.","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"For example, to use a bandpass filter (bpf) on a noise signal,","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"> play(bpf(noise(), 400, 1000.0), 2.0)","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"In general, you're probably looking to use the \"biquad\" filters named lpf, bpf, bpf0 and hpf.","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"For these filters, the filter parameters themselves can be treated as time varying \"signal processes\". This is a common thing in this package – where if it is reasonable to want to be able to vary a parameter over time, it is likely permissible to do so using a signal.","category":"page"},{"location":"tutorial_basic/#Clocks","page":"Basic tutorial","title":"Clocks","text":"","category":"section"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"One kind of a \"signal process\" that is useful in a number of ways, not unlike how phasor is a flexible generator, is the \"clock\". You can create clocks with varying or fixed tempos using clock and Synth.clock_bpm. The values generated by a clock increase monotonically, responding to the instantaneous tempo. Therefore they are useful to schedule events in a virtual time track.","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"While clocks are signals, they don't produce a meaningful sound on their own, so we'll defer their use until later.","category":"page"},{"location":"tutorial_basic/#Basic-realtime-control","page":"Basic tutorial","title":"Basic realtime control","text":"","category":"section"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"A control is a signal whose value can be updated in near realtime. So you can use it to control, for example, the frequency of a sine wave after it has started playing.","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"> f = control()\n> f[] = 440.0\n> play(oscil(0.25, f), 10.0)\n> sleep(1.0)\n> f[] = 880.0\n# Now the frequency of the tone should shift to 880Hz\n# with a little bit of smoothing.","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"Since abrupt changes are usually detrimental to sound processes, control will \"dezipper\" the changes using a simple low pass filter to ensure some degree smoothness to the changes. Given sufficiently small changes, this should work well.","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"control is intended to be useful with a controls exposed via a graphical user interface (work in progress). Until then, you can use it to manipulate signal parameters in real time on the REPL.","category":"page"},{"location":"tutorial_basic/#Fanout","page":"Basic tutorial","title":"Fanout","text":"","category":"section"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"Consider the following piece of code -","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"> s1 = oscil(0.3, 330.0)\n> play(s1 * s1, 2.0)","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"The above arrangement is not permitted as is because the signal s1 can only be \"used\" in one place since it has state. So one of the following must be done instead -","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"You can make a new oscil ...","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"> s1 = oscil(0.3, 330.0)\n> s2 = oscil(0.3, 330.0)\n> play(s1 * s2, 2.0)","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"This has negligible overhead compared to the previous one (assuming it was expected to work, that is). Another approach if you don't really want to make another process like s2, is to wrap the first with the ability to \"fanout\" ...","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"> s1 = fanout(oscil(0.3, 330.0))\n> play(s1 * s1, 2.0)","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"That is fine since s1 is now a singal that can be used in multiple \"receiving positions\".","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"While \"fanin\" is accomplished using regular + operator and is not really a thing done in a programming language without such an operator, \"fanout\" needs to be carefully dealt with when constructing networks of signal processes.","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"Most Signal types in the package don't support fanout by default. So there is a separate fanout operator that wraps such processes with the ability to fanout under the assumption that time always moves monotonically forward. The operator ends up being a no-op for those processes that support fanout on their own.","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"Signal processes which support fanout natively (including Fanout) implement the abstract type SignalWithFanout which is itself a Signal.","category":"page"},{"location":"tutorial_basic/#Stereo-signals","page":"Basic tutorial","title":"Stereo signals","text":"","category":"section"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"Synth.jl is centered around monophonic signals. However, there is some basic support for stereo signals through pan and stereo. ","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"Note: An arbitrary number of channels is seen as a complexity that defeats the pedagogical purpose of this package and will perhaps be added in the future if an appropriate design that maintains the simplicity of the rest of the system is made possible.","category":"page"},{"location":"tutorial_basic/","page":"Basic tutorial","title":"Basic tutorial","text":"Stereo signal processes are represented by the Stereo{L,R} type. You turn two mono signal processes into a stereo signal process using stereo. It is important that the two mono processes support \"fanout\" or are not used anywhere else. This is reflected in the <: SignalWithFanout type constraint. The stereo signal itself is therefore fanout-capable and is a subtype of SignalWithFanout.\nThe usual mono operations of +, * and - are supported on stereo signals directly as well. So you can modulate them and mix them without much fanfare.\nIf you have a stereo signal, you can get at its left and right channels as mono signals using left and right.\nYou can mix down a stereo to a mono signal using mono which will add the left and right channels in the simplest case, but also accepts a \"panner\" signal for more complex mixing.\nrender supports rendering stereo signals.\nA Stereo signal is itself a Signal which when used as a mono signal will result in the mix down of the left and right channels.","category":"page"},{"location":"tx/#Transformers","page":"Transformers","title":"Transformers","text":"","category":"section"},{"location":"tx/","page":"Transformers","title":"Transformers","text":"These operators transform signals in some ways such as mapping ranges (linearmap and expmap), wave shaping (waveshape).","category":"page"},{"location":"tx/","page":"Transformers","title":"Transformers","text":"Synth.waveshape\nSynth.linearmap\nSynth.expmap","category":"page"},{"location":"tx/#Synth.waveshape","page":"Transformers","title":"Synth.waveshape","text":"waveshape(f, sig :: Signal)\nmap(f, sig :: Signal)\n\nMaps a function over the signal. The result is a signal. map and waveshape are aliases for signals.\n\n\n\n\n\n","category":"function"},{"location":"tx/#Synth.linearmap","page":"Transformers","title":"Synth.linearmap","text":"linearmap(a1 :: Real, a2 :: Real, b1 :: Real, b2 :: Real, s :: Signal)\n\nMaps the input signal from its range to a new range.\n\n\n\n\n\n","category":"function"},{"location":"tx/#Synth.expmap","page":"Transformers","title":"Synth.expmap","text":"expmap(a1 :: Real, a2 :: Real, b1 :: Real, b2 :: Real, s :: Signal)\n\nSimilar to the job of linearmap but does exponential interpolated mapping. This implies all four values and the signal value must be positive.\n\n\n\n\n\n","category":"function"},{"location":"tutorial_gens/#Musical-processes","page":"Musical processes","title":"Musical processes","text":"","category":"section"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"The core of Synth.jl deals with \"signal processes\" as described on earlier parts. However, purely working at the signal level alone does not make for \"music\" and we need to be able to orchestrate (a.k.a. \"schedule\") signals with appropriate parameterization in order to make interesting noises.","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"To do this, Synth.jl defines the Gen abstract type with the only method to implement being genproc(::Gen,::Bus,t,rt) :: Tuple{Float64,Gen}.","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"Before we get to it, we need to understand the core \"signal process\" that makes this possible - the bus. ","category":"page"},{"location":"tutorial_gens/#The-bus","page":"Musical processes","title":"The bus","text":"","category":"section"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"A \"bus\" is like a reusable (read \"supports fanout\") line to which various signal processes can write their values by being \"scheduled\" on to the bus using sched. You can use a bus with signals alone for its scheduling capabilities like shown below –","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"> b = bus()\n> play(b, 20)\n> sched(b, oscil(adsr(0.25, 1.0), 440))","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"A few things to note here -","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"We can start playing a bus immediately after creation and it will produce silence until something is scheduled on to it.\nSignals can be scheduled on to the bus using sched to either be played immediately or at a later time. This \"time\" is relative to the start of playback of the bus.\nThe intrinsic duration of a bus is infinite - i.e. if you start playing it without an explicit stop time, it will continue forever.","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"Next, we'll see how to use the bus in conjunction with Gen.","category":"page"},{"location":"tutorial_gens/#Gens","page":"Musical processes","title":"Gens","text":"","category":"section"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"The Gen type abstracts the notion of a \"musical process\" - a process whose task is to schedule musical events on to a bus and to decide the next musical event to follow. In this sense, Gens are define to be \"temporally recursive\", to use the term introduced by Andrew Sorenson. Such a \"musical process\" runs at a far lower temporal granularity than a \"signal process\" – about 60 times a second, compared to the 48000Hz sampling rate. This is fine grained enough for interactivity while the processes can schedule signals in a sample-accurate manner.","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"Several simple noise making \"musical processes\" are available via the tone and ping and it is easy to make your own by defining a subtype of Gen and implementing the genproc(::Gen,::Bus,t,rt) :: Tuple{Float64,Gen} method.","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"The tone provides a number of constructors that facilitate ease of scheduling notes on a timeline.","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"> b = bus()\n> play(b, 20)\n> trk = track([\n         tone(ch([60,64,67]), 1.0),\n         tone(ch(12 .+ [60,62,65,69]), 1.0),\n         ping(72, 1.0),\n         pause(0.5),\n         loop(3, ping([67,72], 0.2)),\n         tone(12 .+ [60, 62, 64, 65, 67, 69, 71, 72, 71, 69, 67, 65, 64, 62, 60], 1/16)\n        ])\n> sched(b, trk)","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"The above sample illustrates the use of track to create sequences, tone to construct simple pitched tones, ch to specify chording, pause to insert pauses and loop to repeat a musical process a set number of times.","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"\"Chording\" refers to playing multiple Gens simultaneously and waiting for all of them to complete before moving on. This is implemented using chord, with overloads of tone supporting chording via ch.","category":"page"},{"location":"tutorial_gens/#Making-your-own-musical-process","page":"Musical processes","title":"Making your own musical process","text":"","category":"section"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"While some basic higher order processes like track and loop are available, t is relatively simple to roll your own as you can find from the code. Below is an example of something that plays all the twelve tones of an octave once with an accelerando.","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"struct AllToneAccel <: Synth.Gen\n    start :: Int\n    finish :: Int\n    dur :: Float64\nend\n\nfunction genproc(g :: AllToneAccel, b :: Bus, t, rt)\n    if g.start > g.finish\n        (t, Cont()) # Indicates that the gen is done and\n                    # the bus must continue with whatever is\n                    # to follow, ex: if this is placed in a track.\n    else\n        # Schedule a tone to be rendered on to the bus at time t.\n        sched(b, t, oscil(adsr(0.25, g.dur), midi2hz(g.start)))\n\n        # Return the next time and the next gen in the sequence.\n        (t + g.dur, AllToneAccel(g.start + 1, g.finish, g.dur * 0.9))\n    end\nend\n\nb = bus(60.0) # 60 beats per minute\nplay(b, 20)\nsched(b, AllToneAccel(60, 84, 1.0))","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"Some things to note –","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"Each proc call decides what comes after as well. This way, we can setup temporal progressions (such as accelerando in the above example) easily.\nAll implemented Gen subtypes are immutable. This is desirable since they can then be reused as simple values across multiple tracks. Since the cost of creating these small structures is very small, new instances can be created when needed, like in the case above where we choose to continue the accelerando.\nEach bus can be given a clock whose tempo can be varied in real time using another signal or a control. This means the tempo of all the events scheduled on the bus can be influenced centrally.\nA musical process is welcome to return any other musical process to follow it. So in that sense, this supports mutual temporal recursion.","category":"page"},{"location":"tutorial_gens/#Recurrent-musical-processes","page":"Musical processes","title":"Recurrent musical processes","text":"","category":"section"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"It is common to make musical processes that appear to maintain a state and evolve it over time, much like ordinary signal processes. So there are  prebuilt \"meta musical processes\" that facilitate this.","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"The simpler one of them is the dyn which can be given a function that will be called a number of times with an index, with the expectation to return a Gen to schedule. It's called a \"dyn\" short for \"dynamic\" because the specific Gen to use can be decided by the function dynamically. Such a dyn does not explicitly use state, though the function passed can be a closure that modifies its state internally on every call (not recommended).","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"b = bus()\nplay(b, 10)\nsched(b, dyn((n,i) -> tone(60+i,0.5), 12, 0))\n# Plays rising semitones, two per second.","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"The more general recurrent process, called rec can be used with functions that need to keep track of state, but without using mutation to do so, so that these Gens can be reused across tracks. Below is the same example above implemented using rec","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"b = bus()\nplay(b, 10)\nsemitones(n,i) = begin\n    if i < n\n        (tone(60+i, 0.5), i+1)\n    else\n        (Cont(), i+1)\n    end\nend\nsched(b, rec(semitones, 12, 0))","category":"page"},{"location":"tutorial_gens/","page":"Musical processes","title":"Musical processes","text":"Both rec and dyn are to be considered as \"dynamic\" because the decision on which Gen to use is made just in time. Hence there is no explicit mention of t in the recurrent function. If you wish to delay the returned Gen by, say, 0.1 seconds, you'll need to sequence it with a pause like seq(pause(0.1), ...the_gen...).","category":"page"},{"location":"gen/#Generators","page":"Generators","title":"Generators","text":"","category":"section"},{"location":"gen/","page":"Generators","title":"Generators","text":"Commonly used generators such as oscillators, phasor (i.e. positive sawtooth) and others. This list will grow a bit over time.","category":"page"},{"location":"gen/","page":"Generators","title":"Generators","text":"oscil is sine wave oscillator, phasor is a sawtooth wave that can also be used as a periodic phase signal, noise is white noise and sample plays back a \"sample\".","category":"page"},{"location":"gen/","page":"Generators","title":"Generators","text":"Synth.oscil\nSynth.phasor\nSynth.saw\nSynth.tri\nSynth.sq\nSynth.noise\nSynth.sample\nSynth.register!","category":"page"},{"location":"gen/#Synth.oscil","page":"Generators","title":"Synth.oscil","text":"oscil(m :: Union{Real,Signal}, f :: Union{Real,Signal}, p :: Union{Real,Signal}; phase = 0.0)\n\nA \"oscil\" is a sinusoidal oscillator whose frequency and amplitude can be varied (\"modulated\") over time. The f argument is expected to be a frequency in Hz units. m determines the amplitude and p the phase in unit range. The phase named argument is a number in the range [0.0,1.0] determining the starting phase within the cycle. It is added to the overall phase evolution as a constant so that oscil can be used for a sine wave with 0.0 as the phase and as a cosine wave with 0.5 as the phase. This lets us do both FM and PM using the same unit. \n\nnote: Design\nAn earlier approach was to have the second argument be a phasor. However, the phasor argument always ended up being passed as phasor(freq) and so it made sense to fold the frequency into oscil as the main control.  This made for a simpler use of oscil, though a tad less general. So essentially oscil(m, f) is equivalent to oscil_v1(m, phasor(f)) where oscil_v1 was the previous version.\n\n\n\n\n\n","category":"function"},{"location":"gen/#Synth.phasor","page":"Generators","title":"Synth.phasor","text":"phasor(f :: Real, phi0 = 0.0)\nphasor(f :: Signal, phi0 = 0.0)\n\nA \"phasor\" is a signal that goes from 0.0 to 1.0 linearly and then loops back to 0.0. This is useful in a number of contexts including wavetable synthesis where the phasor can be used to lookup the wavetable.\n\n\n\n\n\n","category":"function"},{"location":"gen/#Synth.saw","page":"Generators","title":"Synth.saw","text":"saw(f :: Union{Real,Signal}, phi0::Float64 = 0.0)\n\nA protected sawtooth wave (See protect)\n\n\n\n\n\n","category":"function"},{"location":"gen/#Synth.tri","page":"Generators","title":"Synth.tri","text":"tri(f :: Union{Real,Signal}, phi0::Float64 = 0.0)\n\nA protected triangular wave (See protect)\n\n\n\n\n\n","category":"function"},{"location":"gen/#Synth.sq","page":"Generators","title":"Synth.sq","text":"sq(f :: Union{Real,Signal}, phi0::Float64 = 0.0)\n\nA protected square wave (See protect). This is perhaps the harshest of them with a small possibility of aliasing, so the q factor for this is twice the usual.\n\n\n\n\n\n","category":"function"},{"location":"gen/#Synth.noise","page":"Generators","title":"Synth.noise","text":"noise(rng :: AbstractRNG, amp :: Signal)\nnoise(rng :: AbstractRNG, amp :: Real = 1.0f0)\nnoise(amp :: Signal)\nnoise(amp :: Real = 1.0f0)\n\nAmplitude modulatable white noise generator.\n\n\n\n\n\nnoise(rng :: AbstractRNG, amp :: Signal)\nnoise(rng :: AbstractRNG, amp :: Real = 1.0f0)\nnoise(amp :: Signal)\nnoise(amp :: Real = 1.0f0)\n\nAmplitude modulatable white noise generator.\n\n\n\n\n\nnoise(rng :: AbstractRNG, amp :: Signal)\nnoise(rng :: AbstractRNG, amp :: Real = 1.0f0)\nnoise(amp :: Signal)\nnoise(amp :: Real = 1.0f0)\n\nAmplitude modulatable white noise generator.\n\n\n\n\n\nnoise(rng :: AbstractRNG, amp :: Signal)\nnoise(rng :: AbstractRNG, amp :: Real = 1.0f0)\nnoise(amp :: Signal)\nnoise(amp :: Real = 1.0f0)\n\nAmplitude modulatable white noise generator.\n\n\n\n\n\n","category":"function"},{"location":"gen/#Synth.sample","page":"Generators","title":"Synth.sample","text":"sample(samples :: Vector{Float32}; looping = false, loopto = 1.0) \nsample(filename :: AbstractString; looping = false, loopto = 1.0, samplingrate=48000.0, selstart=0.0, selend=Inf)\n\nProduces a sampled signal which samples from the given array as a source. It starts from the beginning and goes on until the end of the array, but can be asked to loop back to a specified point after that.\n\nThe loopto argument is specified relative (i.e. scaled) to the length of the samples vector. So if you want to jump back to the middle, you give 0.5 as the loopto value.\nThe selstart and selend keyword arguments can be used to slice into the sound sample, with the default covering the entire file.\n\nIf the sample rate of the file is different from the selected samplingrate, the loaded samples will be converted to the given rate (uses DSP.resample).\n\nTo make slicing into large files efficient, files are loaded once and cached. This cache is looked up (based on the file name) every time a slice is needed.\n\n\n\n\n\nsample(name :: Symbol) :: Sample\n\nRetrieve named sample. The retrieved sample will have the same looping settings as the stored sample, but not its running state.\n\n\n\n\n\n","category":"function"},{"location":"gen/#Synth.register!","page":"Generators","title":"Synth.register!","text":"register!(name :: Symbol, s :: Sample)\n\nAssociates the given name with the given sample so it can be retrieved using sample(::String).\n\n\n\n\n\nregister!(name :: Symbol, wt :: Vector{Float32})\nregister!(name :: Symbol, wt :: Wavetable)\n\nAssociates the given wave table with the given name so it can be retrieved using wavetable(::String).\n\n\n\n\n\n","category":"function"},{"location":"#Synth.jl-Documentation","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"","category":"section"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"Synth.jl provides a library of signal generators and transformers in a highly compositional form suitable for musical applications. The Signal type is intended to model processes that evolve in time and which could be finite in extent. ","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"For example oscil(0.5, 250.0) is a sine wave oscillator that oscillates at 250Hz with an amplitude of 0.5, forever, and oscil(0.5, 250.0 + oscil(100.0, 250.0)) gives you a frequency modulated sine oscillation and you can impose an envelope on it like this – oscil(adsr(0.5, 1.0), 250.0 + oscil(100.0, 250.0)) – which makes it finite in duration. Most operators can be composed in this manner, usually resulting in fairly efficient code as well. See the Models section for some other simple signal combinations such as Synth.Models.basicvocoder.","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"The above constructed finite extent signal can be rendered to a SampledSignals.SampleBuf using render like this –","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"v = render(oscil(adsr(0.5, 1.0), 250.0 + oscil(100.0, 250.0)))","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"(Pass an explicit duration if it's an infinite extent signal or use play.)","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"Signals can be rendered to SampleBuf buffers, to raw Float32 files or in real time to the computer's sound output using play. There is also some minimal support for stereo signals.","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"Combined with the bus mechanism, the notion of a process for producing both sound and audio events can be expressed quite nicely using this API. An example below - ","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"using Synth\n\nb = bus(60.0)\nplay(0.3 * b, 20.0)\nnonsense_tests = [\n         tone(ch([60,64,67]), 1.0),\n         tone(ch(12 .+ [60,62,65,69]), 1.0),\n         ping(72, 1.0),\n         pause(0.5),\n         loop(3, ping([67,72], 0.2)),\n         tone(12 .+ [60, 62, 64, 65, 67, 69, 71, 72, 71, 69, 67, 65, 64, 62, 60], 1/16)\n        ]\nsched(b, track(nonsense_tests))\nsleep(10.0)","category":"page"},{"location":"#The-Signal-type","page":"Synth.jl Documentation","title":"The Signal type","text":"","category":"section"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"Synth.Signal","category":"page"},{"location":"#Synth.Signal","page":"Synth.jl Documentation","title":"Synth.Signal","text":"abstract type Signal end\n\nA Signal represents a process that can be asked for a value for every tick of a clock. We use it here to represent processes that produce audio and control signals to participate in a \"signal flow graph\". While mathematically signals can be treated as though they were infinite in duration, signals are in practice finite in duration for both semantic and efficiency reasons (ex: managing voices as a constrained resource).\n\nTo construct signals and to wire them up in a graph, use the constructor functions provided rather than the structure constructors directly.\n\nThe protocol for a signal is given by two functions with the following signatures –\n\ndone(s :: Signal, t, dt) :: Bool\nvalue(s :: Signal, t, dt) :: Float32\n\nAs long as you implement these two methods, you can define your own subtype of Signal and use it with the library.\n\nThe renderer will call done to check whether a signal has completed and if not, will call value to retrieve the next value. The contract with each signal type is that even if value is called for a time after the signal is complete, it should return sample value 0.0f0 or a value appropriate for the type of signal. This is so that done can be called per audio frame rather than per sample.\n\nAddition, subtraction and multiplication operations are available to combine signals and numbers. Currently signals are single channel only.\n\nChoice of representation\n\nA number of approaches are used in computer music synth systems -\n\nBlocks and wires paradigm: ... where blocks represent signal processing modules and wires represent connections and signal flow between these modules. Even within this paradigm there are different semantics to how the signal flow is handled, from asynchronous/non-deterministic, to fully deterministic flow, to buffer-wise computation versus sample-wise computation. The WebAudioAPI, for example, takes this approach and performs buffer-wise computation in blocks of 128 samples. It is rare to find a synth library that works sample-wise in this mode.\nFunctional: ... where signals are mathematical constructs that can be combined using operators to construct new signals. Usually this paradigm manifests as a textual programming language, like SuperCollider and Chuck (which has elements of the above approach too).\n\nThe approach taken in this library is to combine the notion of a signal with the computation that produces the signal - a rough analog of \"constructive real numbers\". In other words, a \"signal\" – i.e. a stream of values regularly spaced in time – is identified with a computation that produces the stream.\n\nThis permits manipulating signals like mathematical objects that can be combined, while modelling \"signal flow\" via ordinary functions in programming that call other functions recursively. Without further thought, this approach will only permit \"signal flow trees\", where the output of a processing step can only be fed into a single input due to the nature of function composition being used to construct the signal flow pattern. However, with the fanout operator, it becomes possible to reuse a signal as input for more than one processing block, extending the scope to include \"signal flow DAGs\". The feedback operator further extends this possibility through late binding of signal connections to permit loops in the graph, truly getting us \"signal flow graphs\" that can support feedback loops, albeit with a single sample delay.\n\nThe library exploits Julia's \"optimizing just-ahead-of-time compilation\" to describe each signal computation function in a per-sample fashion so that sample frames can be computed efficiently by the renderer. In other languages including AoT compiled languages like C, this combination of simplicity of API with high performance will be very hard to get. In dynamic languages, the function call overhead is even worse and not easily eliminated due to weak type systems. You'll notice how the rich type information about how a signal was constructed is maintained in the final result so that the renderer can compile it down to efficient code, often eliminating intermediate function calls.\n\nRealtime usage necessitates some amount of dynamic dispatch, but it is still possible to mark boundaries whether the type knowledge can help create efficient code.\n\nThe end result of all this is that you can combine signals like ordinary math and expect complex signal flow graphs to work efficiently, even in realtime.\n\n\n\n\n\n","category":"type"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"The definition of Signal treats signal generators and transformers like \"values\" which can be operated on using ordinary arithmetic +, - and *.","category":"page"},{"location":"#Models","page":"Synth.jl Documentation","title":"Models","text":"","category":"section"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"Modules = [Synth.Models]\nOrder   = [:function, :type]","category":"page"},{"location":"#Synth.Models.additive","page":"Synth.jl Documentation","title":"Synth.Models.additive","text":"additive(f0,\n         amps :: AbstractVector{Union{Real,Signal}},\n         detune_factor :: Signal = konst(1.0f0))\n\nSimple additive synthesis. amps is a vector of Float32 or a vector of signals. f0 is a frequency value or a signal that evaluates to the frequency. The function constructs a signal with harmonic series based on f0 as the fundamental frequency and amplitudes determined by the array amps.\n\n\n\n\n\n","category":"function"},{"location":"#Synth.Models.basicvocoder-NTuple{4, Any}","page":"Synth.jl Documentation","title":"Synth.Models.basicvocoder","text":"basicvocoder(sig, f0, N, fnew; bwfactor = 0.2, bwfloor = 20.0)\n\nA simple vocoder for demo purposes. Takes N evenly spaced frequencies k f_0 and moves them over to a new set of frequencies k f_textnew using a heterodyne filter.  The bwfactor setting gives the fraction of the inter-frequency bandwidth to filter in. The bandwidth has a floor given by bwfloor in Hz.\n\n\n\n\n\n","category":"method"},{"location":"#Synth.Models.chirp-NTuple{4, Any}","page":"Synth.jl Documentation","title":"Synth.Models.chirp","text":"chirp(amp, startfreq, endfreq, dur;\n      shapename::Union{Val{:line},Val{:expon}} = Val(:line))\n\nA \"chirp\" is a signal whose frequency varies from a start value to  a final value over a period of time. The shape of the change can be controlled using the shapename keyword argument.\n\n\n\n\n\n","category":"method"},{"location":"#Synth.Models.drumkit-Tuple{AbstractString, AbstractString}","page":"Synth.jl Documentation","title":"Synth.Models.drumkit","text":"drumkit(kit::AbstractString, dir::AbstractString) :: DrumKit\ndrumkit(kit::AbstractString) :: DrumKit\n\nLoads a \"standard\" drum kit consisting of a kick, hihat, snare and three toms. kit gives the name of the kit to load and maps to the name of a directory under the given dir. If dir is omitted, then the kits included within Synth.jl are scanned.\n\nUsage:\n\nusing Synth.Models: drumkit\n\nk = drumkit(\"Techno\")\nplay(track([hit(k.kick, 0.5), pause(0.5), hit(k.snare, 0.5)]), 2.0)\n\nSee also hit\n\n\n\n\n\n","category":"method"},{"location":"#Synth.Models.fm","page":"Synth.jl Documentation","title":"Synth.Models.fm","text":"fm(carrier, modulator, index, amp = konst(1.0f0))\n\nBasic FM synth module. carrier is the carrier frequency that can itself be a signal. modulator is the modulation frequency and index is the extent of modulation. amp, if given decides the final amplitude. All of them can vary over time.\n\nExample\n\nplay(fm(220.0f0, 550.0f0, 100.0f0), 5.0)\n\n\n\n\n\n","category":"function"},{"location":"#Synth.Models.hit","page":"Synth.jl Documentation","title":"Synth.Models.hit","text":"hit(samplefile::AbstractString, vel::Real = 1.0f0) :: DrumHit\nhit(drum::DrumHit, vel::Real = 1.0f0) :: DrumHit\n\nConstructs a DrumHit that can be used in Gen compositions. Drum hits have an inherent duration of 0.0. So if you want to put a  gap between two drum hits, you'll need to use pause. hit will load the sample and cache it so the loading doesn't happen at actual play time.\n\nUsage: play(track([hit(\"kick.wav\", 0.5), pause(0.5), hit(\"snare.wav\", 0.5)]), 2.0)\n\nSee also Synth.Models.drumkit\n\n\n\n\n\n","category":"function"},{"location":"#Synth.Models.ising2-NTuple{6, Synth.Signal}","page":"Synth.jl Documentation","title":"Synth.Models.ising2","text":"ising2(f :: Signal, b1 :: Signal, b2 :: Signal, x1 :: Signal, x2 :: Signal, w12 :: Signal)\n\nExperimental 2-qubit \"Ising\" model with controllable weights. Not very interesting at this point, but perhaps with more qubits it might get interesting as the number of frequencies that get mixed in will increase, producing a richer sound.\n\n\n\n\n\n","category":"method"},{"location":"#Synth.Models.snare-Tuple{Real}","page":"Synth.jl Documentation","title":"Synth.Models.snare","text":"snare(dur::Real; rng = MersenneTwister(1234))\n\nVery simple snare hit where the dur is the \"half life\" of the snare's decay. Just amplitude modulates some white noise.\n\n\n\n\n\n","category":"method"},{"location":"#Synth.Models.tone-Tuple{Any, Any, Any}","page":"Synth.jl Documentation","title":"Synth.Models.tone","text":"tone(amp, freq, duration; attack_factor = 2.0, attack_secs = 0.005, decay_secs = 0.05, release_secs = 0.2)\n\nA simple sine tone modulator by an ADSR envelope. amp is the amplitude of the sustain portion, freq is the Hz value of the frequency of the tone and duration is the duration in seconds of the sustain portion.\n\nEnvelope characteristics\n\nattack_factor - the factor (usually > 1.0) that multiplies the amplitude value to  determine the peak of the attack portion of the envelope.\nattack_secs - the duration of the attack portion. This should be kept short in general.\ndecay_secs - the duration of the portion of the envelope where it decays from the peak attack value down to the sustain level.\nrelease_secs - the \"half life\" of the release portion of the envelope. Over this time, the amplitude of the signal will decay by a factor of 2.\n\n\n\n\n\n","category":"method"},{"location":"#Synth.Models.DrumHit","page":"Synth.jl Documentation","title":"Synth.Models.DrumHit","text":"Represents a sampled drum sound to be played without a \"duration\". You can use the [hit])(@ref \"Synth.Models.hit\") function with it to reuse it with a different velocity.\n\nsamplefile - file name of the sample containing the drum hit.\nvel - the velocity of the hit - in the range [0.0,1.0].\n\n\n\n\n\n","category":"type"},{"location":"#Synth.Models.DrumKit","page":"Synth.jl Documentation","title":"Synth.Models.DrumKit","text":"Collects together a number of \"standard\" drums belonging to a \"kit\".\n\n\n\n\n\n","category":"type"},{"location":"#Index","page":"Synth.jl Documentation","title":"Index","text":"","category":"section"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"","category":"page"}]
}
