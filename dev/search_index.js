var documenterSearchIndex = {"docs":
[{"location":"wt/#Wavetable-synthesis","page":"Wavetable synthesis","title":"Wavetable synthesis","text":"","category":"section"},{"location":"wt/","page":"Wavetable synthesis","title":"Wavetable synthesis","text":"Common synthesis technique used in sampling synths.","category":"page"},{"location":"wt/","page":"Wavetable synthesis","title":"Wavetable synthesis","text":"Synth.wavetable\nSynth.maketable","category":"page"},{"location":"wt/#Synth.wavetable","page":"Wavetable synthesis","title":"Synth.wavetable","text":"wavetable(table :: Vector{Float32}, amp :: Signal, phase :: Signal)\n\nA simple wavetable synth that samples the given table using the given phasor and scales the table by the given amplitude modulator. A copy of the given table is stored.\n\nThe wavetable is a simple array of samples, often in the same sampling rate as the output audio end point, but not necessarily so. The phase signal, which can be generated using phasor, has values in the range 01 with 0 mapping to the start of the wave table and 1 to the end. To be precise, if the wave table has N samples, then the phase values in the range 01N) will map to the first sample at index 1 and the sample at index k will be chosen by phase value in the range (k-1)N kN).\n\nThe wavetable processor does 4-point interpolation. This means you can take a small sample table and stretch it out using the interpolation by using a slowly varying phasor. This is how the \"pitch\" of the sample gets changed during synthesis.\n\nThe amplitude modulation is just as with sinosc.\n\nThe samples wave table is deemed to be completed when the phasor signal or the amplitude modulator signal are completed.\n\nnote: Envelopes\nIt is common for the output of such a wavetable \"voice\" to be modulated using an envelope like adsr. You can therefore pass such an ADSR signal as the amp argument. If the phase signal is infinite in extent, then the lifetime of the wavetable voice will become determined by the lifetime of the ADRS envelope.\n\nnote: Attack and release\nA complete voice implementation using a wavetable synth will need some extra niceties like a leading fragment of sound used during the \"attack\" phase of the voice until the voice begins to systain, and perhaps switching to a different voice during the release phase with a bit of cross fade. The current implementation provides a primitive that can be composed with other units in order to make such a more complete voice. The complexity of computing this voice will then be a bit more than the basic wavetable voice, but not much more than if you'd hand coded it yourself, thanks to Julia.\n\nnote: Sustain loop\nThe phasor determines the section of the wavetable that is looped. To loop without a glitch (which can result in many undesirable harmonics), the value and slope at the start and end of the looping section will usually have to be matched. For some kinds of samples, this can be accomplished by putting the wavtable output through an appropriate low pass filter (using lpf), but it is even better to do the alignment and filter the result.\n\n\n\n\n\n","category":"function"},{"location":"wt/#Synth.maketable","page":"Wavetable synthesis","title":"Synth.maketable","text":"maketable(L :: Int, f)\n\nUtility function to construct a table for use with wavetable. f is passed values in the range [0.0,1.0] to construct the table of the given length L.\n\n\n\n\n\n","category":"function"},{"location":"stereo/#Stereo-signals","page":"Stereo signals","title":"Stereo signals","text":"","category":"section"},{"location":"stereo/","page":"Stereo signals","title":"Stereo signals","text":"The primary entities this package deals with are mono signals. However, some basic support for stereo signals is included as well using the stereo operator that clubs two mono signals to make a stereo signal. Such a \"stereo\" signal behaves like the mixed version when used as an ordinary Signal. However there are other methods that support various operations, including rendering to stereo.","category":"page"},{"location":"stereo/","page":"Stereo signals","title":"Stereo signals","text":"Pick the left/right/mixed channels of a stereo signal using left, right and [mono])@ref). Pan a mono or stereo signal left/right using pan.","category":"page"},{"location":"stereo/","page":"Stereo signals","title":"Stereo signals","text":"Synth.stereo\nSynth.left\nSynth.right\nSynth.mono\nSynth.pan","category":"page"},{"location":"stereo/#Synth.stereo","page":"Stereo signals","title":"Synth.stereo","text":"stereo(left :: Fanout{L}, right :: Fanout{R}) where {L <: Signal, R <: Signal}\nstereo(left :: Signal, right :: Signal)\n\nMakes a \"stereo signal\" with the given left and right channel signals. The stereo signal is itself considered a signal which produces the mixed output of the left and right channels. However, you can pick out the left and right channels separately using left and right which produce fanout versions of the two components.\n\nnote: Aliasability\nStereo signals are fanout without calling fanout on them. The first method assumes that you're passing in fanout signals (recommended). The second will make them fanout, before storing a reference, so you should subsequently access the individual channels only via the left and right methods.\n\nThere is a new value method that works on stereo signals –\n\nvalue(s::Stereo{L,R}, chan::Int, t, dt)\n\nwhere chan can be -1 for left, 0 for mixed middle and 1 for right channels. Note that calling value for different channels at the same time won't compute multiple times because Stereo is fanout directly.\n\nThe mixer and modulator operators (+/-/*) treat stereo signals as stereo and work accordingly. The other operators all (unless noted) are not cognizant of stereo signals and so you must be explicit with them if you're applying them on stereo signals.\n\nSee also: left, right and mono\n\n\n\n\n\n","category":"function"},{"location":"stereo/#Synth.left","page":"Stereo signals","title":"Synth.left","text":"left(s :: Stereo{L,R}) where {L <: Signal, R <: Signal}\nleft(s :: Signal)\n\nPicks the left channel of a stereo signal. Evaluates to the signal itself if passed a non-stereo signal (which is considered mono).\n\nSee also: right, mono and stereo\n\n\n\n\n\n","category":"function"},{"location":"stereo/#Synth.right","page":"Stereo signals","title":"Synth.right","text":"right(s :: Stereo{L,R}) where {L <: Signal, R <: Signal}\nright(s :: Signal)\n\nPicks the right channel of a stereo signal. Evaluates to the signal itself if passed a non-stereo signal (which is considered mono).\n\nSee also: left, mono and stereo\n\n\n\n\n\n","category":"function"},{"location":"stereo/#Synth.mono","page":"Stereo signals","title":"Synth.mono","text":"mono(s :: Stereo{L,R}) where {L <: Signal, R <: Signal} \nmono(s :: Stereo{L,R}, panval :: Union{Realm,Signal}) where {L <: Signal, R <: Signal}\nmono(s :: Signal)\n\nConverts a stereo signal into a mono signal by mixing the left and right channels. Evaluates to the signal itself if passed a non-stereo signal (which is considered mono).\n\nIn the version that takes a pan value, passing 1.0f0 will result in only the right channel being selected. Passing -1.0f0 will result in only the left channel being selected and intermediate values will linearly mix the two channels. You can think of the panval argument as where your ear is  being directed. If you direct it to the right, you hear the right channel, and if you direct it to the left, you hear the left channel sound.\n\nSee also: left, right and stereo\n\n\n\n\n\n","category":"function"},{"location":"stereo/#Synth.pan","page":"Stereo signals","title":"Synth.pan","text":"pan(s :: Signal, lr :: Real)\npan(s :: Signal, lr :: Signal)\npan(s :: Stereo{L,R}, lr :: Real) where {L,R}\n\nPans a mono signal left or right to produce a stereo signal. lr is a signal that takes values in the range [-1.0,1.0] where negative values indicate left and positive values indicate right. So giving 0.0 will centre pan the signal with left and right components receiving equal contributions of the signal.\n\nWhen applied to a stereo signal, a \"left pan\" (lr in range [-1,0]) will result in the right signal being moved left  and a \"right pan\" (lr in range [0,1]) will result in the left signal being moved right.\n\n\n\n\n\n","category":"function"},{"location":"gran/#Granular-synthesis","page":"Granular synthesis","title":"Granular synthesis","text":"","category":"section"},{"location":"gran/","page":"Granular synthesis","title":"Granular synthesis","text":"A popular cool synthesis technique that can use sampling to produce a wide variety of rich and complex sounds. A phasor is used to trigger grains on the negative edge.","category":"page"},{"location":"gran/","page":"Granular synthesis","title":"Granular synthesis","text":"granulate is the main synthesis routine that takes as \"granulator\" function like simplegrains or chorusgrains.","category":"page"},{"location":"gran/","page":"Granular synthesis","title":"Granular synthesis","text":"Synth.granulate\nSynth.simplegrains\nSynth.chorusgrains\nSynth.Granulation\nSynth.Grain","category":"page"},{"location":"gran/#Synth.granulate","page":"Granular synthesis","title":"Synth.granulate","text":"granulate(samples, dur :: Real, overlap :: Real, speed :: Real, graintime,\n          player = phasor(1.0 * speed / (dur * (1.0 - overlap)))\n          ; samplingrate=48000.0f0)\ngranulate(samples::Vector{Float32}, granulator, speed::Signal, graintime::Signal, player::Signal; samplingrate=48000.0f0)\n\nGranular synthesis - simple version.\n\nThe granulator is a function of time that returns a vector of grains. Two built-in granulators are available – simplegrains and chorusgrains. The player is expected to be a phasor which will trigger grains on the negative edge.\n\nExample\n\n    snd = read_rawaudio(\"/tmp/somefile.raw\")\n    stop = play(0.5 * granulate(snd, \n                             chorusgrains(rng,0.0,3,4.0),\n                             konst(0.5),\n                             line(0.0, 10.0, 3.2),\n                             phasor(20.0)),\n             10.0)\n\n\n\n\n\n","category":"function"},{"location":"gran/#Synth.simplegrains","page":"Granular synthesis","title":"Synth.simplegrains","text":"simplegrains(dur :: Real, overlap :: Real, speedfactor :: Real)\n\nResult is a function(time) which when called will produce a vector of a single grain. This kind of a function is what we call a \"granulator\" (see granulate).\n\n\n\n\n\n","category":"function"},{"location":"gran/#Synth.chorusgrains","page":"Granular synthesis","title":"Synth.chorusgrains","text":"chorusgrains(rng, delayspread=0.0, N=1, spread=5.0f0)\n\nResult is a function(time) which when called will produce a vector of N grains spread in time. Since the chorus spread has some randomness to it, you need to pass an RNG. This kind of function is called a \"granulator\" (see granulate).\n\n\n\n\n\n","category":"function"},{"location":"gran/#Synth.Granulation","page":"Granular synthesis","title":"Synth.Granulation","text":"Represents a granulation of a sample array.\n\nThe grain durations, overlaps and playback speed can be varied with time as signals. Additionally, the grainplayphasor is  expected to be a phasor that will trigger a new grain voice upon its negative edge.\n\n\n\n\n\n","category":"type"},{"location":"gran/#Synth.Grain","page":"Granular synthesis","title":"Synth.Grain","text":"An internal structure used to keep track of a single granular \"voice\".\n\nrt is the time within the grain. 0.0 is the start of the grain.\ngt is the grain start time within the larger sample array.\ndur is the grain duration in seconds\noverlap is also a duration in seconds. The total duration of the grain  is dependent on both dur and overlap.\n\n\n\n\n\n","category":"type"},{"location":"basic/#Basic-signals","page":"Basic signals","title":"Basic signals","text":"","category":"section"},{"location":"basic/","page":"Basic signals","title":"Basic signals","text":"These are commonly used operators that either make signals directly or transform signals in some way. Some key concepts to pay attention to include fanout and feedback.","category":"page"},{"location":"basic/","page":"Basic signals","title":"Basic signals","text":"Synth.konst\nSynth.clip\nSynth.sigfun\nSynth.fanout\nSynth.feedback\nSynth.connect\nSynth.clock\nSynth.clock_bpm\nSynth.clamp\nSynth.mix\nSynth.modulate","category":"page"},{"location":"basic/#Synth.konst","page":"Basic signals","title":"Synth.konst","text":"konst(v::Real)\n\nMakes a constant valued signal. Useful with functions that accept signals but we only want to use a constant value for it.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.clip","page":"Basic signals","title":"Synth.clip","text":"clip(dur :: Float64, s :: Signal)\n\nClips the given signal to the given duration. Usually you'd use a \"soft\" version of this like a raised cosine or ADSR, but clip could be useful on its own.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.sigfun","page":"Basic signals","title":"Synth.sigfun","text":"sigfun(f::Function) :: SigFun\n\nTreats a simple function of time (in seconds) as a signal.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.fanout","page":"Basic signals","title":"Synth.fanout","text":"fanout(s :: Signal)\n\nA signal, once constructed, can only be used by one \"consumer\" via structure composition. In some situations, we want a signal to be plugged into multiple consumers (to make a signal flow DAG). For these occasions, make the signal fanout by calling fanout on it and use the aliasble signal everywhere you need it instead. Note that fanout is an idempotent operator (i.e. if s = fanout(sig), then fanout(s) = s).\n\nnote: Constraint\nIt only makes sense to make a single fanout version of a signal. Repeated evaluation of a signal is avoided by fanout by storing the recently computed value for a given time. So it assumes that time progresses linearly.\n\nnote: Terminology\nThe word \"alias\" has two meanings - one in the context of signals where frequency shifting it can cause wrap around effects in the spectrum due to sampling, and in the context of a programming language where a value referenced in multiple data structures is said to be \"aliased\". It is in the latter sense that we use the word fanout in this case. \n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.feedback","page":"Basic signals","title":"Synth.feedback","text":"feedback()\n\nConstructs a feedback node which can be connected to a signal later on after construction. This is intended to be used in feedback loops and introduces a single sample delay to prevent infinite recursion.\n\nYou can later on connect a signal to the feedback point by calling connect(::Signal,::Feedback). Just as fanout is used to make DAG signal flow graphs possible, feedback is used to make graphs with loops possible.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.connect","page":"Basic signals","title":"Synth.connect","text":"connect(s :: Signal, fb :: Feedback)\n\nConnects a signal to a feedback point.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.clock","page":"Basic signals","title":"Synth.clock","text":"clock(speed :: Real, t_end :: Real = Inf)\nclock(speed :: Signal, t_end :: Real = Inf)\n\nConstructs different kinds of clocks. Clocks can be speed controlled. Clocks used for audio signals should be made using the clock constructor and those for scheduling purposes using clock_bpm.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.clock_bpm","page":"Basic signals","title":"Synth.clock_bpm","text":"clock_bpm(tempo_bpm=60.0, t_end :: Real = Inf) :: Signal\nclock_bpm(tempo_bpm :: Signal, t_end :: Real = Inf) :: Signal\n\nConstructs different kinds of clocks. Clocks can be speed controlled. Clocks used for audio signals should be made using the clock constructor and those for scheduling purposes using clock_bpm.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.clamp","page":"Basic signals","title":"Synth.clamp","text":"clamp(minval::Real, maxval::Real, sig::Signal)\nclamp(minval::Real, maxval::Real, sig::Stereo{L,R}) where {L <: Signal, R <: Signal}\n\nClamps the given signal to the give minimum and maximum values.  Supports stereo signals and clamps the individual channels.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.mix","page":"Basic signals","title":"Synth.mix","text":"mix(w1 :: Real, s1 :: Signal, w2 :: Real, s2 :: Signal)\n\nCreates a mixed signal from the two given signals, using the two  constant weights. This is the basis of the support for + and - between signals. This and modulate remove some unnecessary combinations and reduce them down to simpler forms where possible.\n\n\n\n\n\n","category":"function"},{"location":"basic/#Synth.modulate","page":"Basic signals","title":"Synth.modulate","text":"modulate(m :: Signal, s :: Signal)\n\nBasically performs multiplication between two signals and is the basis of * operator support. This and mix together implement some expression simplifications that remove unnecessary combinations.\n\n\n\n\n\n","category":"function"},{"location":"render/#Rendering","page":"Rendering","title":"Rendering","text":"","category":"section"},{"location":"render/","page":"Rendering","title":"Rendering","text":"Rendering a signal to samples, saving to a file and reading raw float32 from a file. For more support, use FileIO, WAV and such modules.","category":"page"},{"location":"render/","page":"Rendering","title":"Rendering","text":"render renders to a buffer in memory, Synth.write writes to a raw audio file and read_rawaudio reads in a raw float32 sample file into a buffer for playback.","category":"page"},{"location":"render/","page":"Rendering","title":"Rendering","text":"Synth.render\nSynth.write\nSynth.read_rawaudio","category":"page"},{"location":"render/#Synth.render","page":"Rendering","title":"Synth.render","text":"render(s :: Signal, dur_secs; samplingrate=48000, normalize=false, maxamp=0.5)\nrender(s :: Stereo{L,R}, dur_secs; samplingrate=48000) where {L <: Signal, R <: Signal}\n\nRenders the given signal to a flat Vector{Float32}, over the given dur_secs. If the signal terminates before the duration is up, the result is truncated accordingly. These functions return SampleBuf from SampledSignals package.\n\n\n\n\n\n","category":"function"},{"location":"render/#Synth.write","page":"Rendering","title":"Synth.write","text":"write(filename :: AbstractString, model::Signal, duration_secs :: AbstractFloat; samplingrate=48000, maxamp=0.5)\n\nRenders and writes raw Float32 values to the given file.\n\n\n\n\n\n","category":"function"},{"location":"render/#Synth.read_rawaudio","page":"Rendering","title":"Synth.read_rawaudio","text":"read_rawaudio(filename :: AbstractString)\n\nReads raw Float32 values from the given file into a Vector{Float32} that can then be used with sample or wavetable.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Filters","page":"Filters","title":"Filters","text":"","category":"section"},{"location":"filters/","page":"Filters","title":"Filters","text":"Linear time invariant first and second filters, with controllable filter parameters. Main ones are lpf, hpf and bpf second order filters. Also, delay and tap make a delay line that can be tapped at multiple points.","category":"page"},{"location":"filters/","page":"Filters","title":"Filters","text":"Synth.filter1\nSynth.filter2\nSynth.fir\nSynth.lpf\nSynth.bpf\nSynth.bpf0\nSynth.hpf\nSynth.delay\nSynth.tap\nSynth.maxdelay","category":"page"},{"location":"filters/#Synth.filter1","page":"Filters","title":"Synth.filter1","text":"filter1(s :: Signal, gain :: Signal)\n\nA first order filter where the gain factor that controls the bandwidth of the filter can be live controlled.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.filter2","page":"Filters","title":"Synth.filter2","text":"filter2(s :: Signal, f :: Signal, g :: Signal)\nfilter2(s :: Signal, f :: Signal, g :: Real)\nfilter2(s :: Signal, f :: Real, g :: Real)\n\nConstructs a second order filter where the frequency and the gamma can be controlled live.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.fir","page":"Filters","title":"Synth.fir","text":"fir(filt :: Vector{Float32}, sig :: Signal)\n\nConstructs a \"finite impulse response\" (FIR) filter with the given filt as the impulse response. Keep the filt argument short (to within about 1000 samples) in order for fir to be able to perform in realtime. The algorithm used is not suitable for very large FIR filter lengths ... which we'll perhaps add in the future.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.lpf","page":"Filters","title":"Synth.lpf","text":"lpf(sig :: Signal, freq, q; samplingrate=48000)\n\nStandard second order LPF with frequency and Q factor.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.bpf","page":"Filters","title":"Synth.bpf","text":"bpf(sig :: Signal, freq, q; samplingrate=48000)\n\nStandard second order bandpass filter with given centre frequency and Q factor. \n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.bpf0","page":"Filters","title":"Synth.bpf0","text":"bpf0(sig :: Signal, freq, q; samplingrate=48000)\n\nStandard second order bandpass filter with given centre frequency and Q factor. This variant of bpf gives constant 0dB peak gain instead of the peak gain being determined by Q.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.hpf","page":"Filters","title":"Synth.hpf","text":"hpf(sig :: Signal, freq, q; samplingrate=48000)\n\nStandard second order high pass filter with given cut off frequency and Q.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.delay","page":"Filters","title":"Synth.delay","text":"delay(sig :: Signal, maxdelay :: Real; samplingrate=48000)\n\nSets up a delay ring buffer through which the given signal is passed.  A delay is pretty much a pass through and is useful only in conjunction with tap. A delay can fanout on its own, which means you can make multiple tap points on the same delay based on time varying tap locations.\n\nsig is the signal that is delayed.\nmaxdelay is the maximum amount of delay possible.\nsamplingrate is the sampling rate in Hz. (This is needed to compute buffer size.)\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.tap","page":"Filters","title":"Synth.tap","text":"tap(d :: Delay, t :: Signal)\ntap(d :: Delay, t :: Real)\n\nYou can setup multiple time varying tap points on a delay line by calling tap multiple times and using it elsewhere. Since a delay is intrinsically fanout capable, this is possible without further ado.\n\n\n\n\n\n","category":"function"},{"location":"filters/#Synth.maxdelay","page":"Filters","title":"Synth.maxdelay","text":"maxdelay(sig :: Delay)\n\nReturns the maximum delay (in seconds) supported by the given delay unit.\n\n\n\n\n\n","category":"function"},{"location":"faq/#FAQ","page":"FAQ","title":"FAQ","text":"","category":"section"},{"location":"faq/#How-to-make-a-signal-processor/generator-that-has-multiple-outputs?","page":"FAQ","title":"How to make a signal processor/generator that has multiple outputs?","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"The type Synth.Signal and its methods done and value imply that a signal is a single value at a point in time. So how do we represent multi-output signal processors using this approach?","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"If the outputs of a process are all to be computed synchronously in the same time step, then we can split the computation and access into two separate signals. While the main processing step computes all the outputs in its value implementation, it can output one chosen value, keeping the others as state in its structure.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"We can have secondary access signals which then pick out any of the many computed outputs so it can be composed with other parts of the signal flow graph.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"When using this approach, it is important that the main (multi-output) signal processing module supports fanout - so that a value call will do the computation only once for a given time t. ","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"For an example of this approach, see the implementation of the delay and tap signals. The delay line is modeled as a pass-through signal that keeps some history, and the tap is modeled as referencing a point within the history stored by an underlying delay line. This permits the creation of as many taps on a single delay line with their own individual controls as needed, even dynamically if necessary. In other systems, the number of tap points is usually specified up front for delay lines.","category":"page"},{"location":"faq/#How-to-time-limit-an-infinite-extent-signal-like-[sinosc](@ref)?","page":"FAQ","title":"How to time limit an infinite extent signal like sinosc?","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Several signals like sinosc are in principle infinitely extended in time. So when they're put to musical applications, various envelopes are applied to them to give the impression of musical \"events\" happening (such as \"a note\").","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"A plain way to limit the duration of a sinosc is to use clip like this - clip(0.4, sinosc(0.5f0, 330.0)). This will sharply delimit the waveform (whatever it happens to be and not just sinosc) to a duration of (in our example) 0.4 seconds.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"A sharp delineation like clip is useful in some circumstances as a guard, but with specific notes. However, it can produce a \"click\" – i.e. a sudden change in signal level – at the start and end and such clicks are quite unmusical, to say the least. Therefore you usually apply an \"envelope\" like a raised cosine or an adsr to the amplitude like this – sinosc(adsr(1.0f0, 0.4), 330.0). Now, the lifetime of the signal will be determined by the duration of the ADSR envelope since there are no other facets that determine the duration.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Most signals and signal transformers use their dependent signals to determine their duration and an \"in principle infinite\" signal like sinosc is one of them. So you could clip the time extent of the frequency component as well, like this – sinosc(0.5f0, clip(0.4, konst(330.0))). This will get rid of \"first order clicks\" in the output due to phase continuity, since the phase is determined by integrating the frequency. However, you'll hear a second order click since the rate at which the signal is changing suddenly changes and our ears pick that up.","category":"page"},{"location":"faq/#How-to-mix-two-signals-with-weights?","page":"FAQ","title":"How to mix two signals with weights?","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Mixing signals is a common operation needed and Synth makes it easy by supporting ordinary mathematical operations +, - and * on the Signal type entities. This means that if you have two signals a and b that you want 25%/75% mix of, you can do this – s = 0.25f0 * a + 0.75f0 * b.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"If you wish to, you can also use the mix and [modulate])(@ref) methods directly. They underpin the arithmetic operators which are mere convenience wrappers for them.","category":"page"},{"location":"faq/#How-do-I-play-a-stereo-composition?","page":"FAQ","title":"How do I play a stereo composition?","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"The Synth package primarily deals with monophonic signals since they're easy to compose. The composition properties of multi-channel signals are ambiguous at best. So this package makes stereo signals somewhat second class citizens, though there is some support. See stereo for info about how to construct and work with stereo signals.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"The approach taken in this package is that if there is an obvious way to compose stereo signals, it is usually supported. If there is some choice to be made, it is left to the user to effect that choice since sufficient lower level operations are available.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"stereo turns a pair of monophonic signals into a stereo signal.\nleft and right fetch the L and R components of a stereo signal. They don't bomb on mono signals and produce those as is for compatibility.\nOperators which support being applied on stereo signals will usually \"lift\" the stereo composition out and push the operation into the components of the signal. So it is somewhat unusual to have a stereo signal embedded deep into a composition tree that produces a mono signal in the end.\nrender and play support steroo signals directly.","category":"page"},{"location":"faq/#How-do-I-use-microphone-input?","page":"FAQ","title":"How do I use microphone input?","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"TODO: As of this writing, there is no support for audio input. Will be added soon enough.","category":"page"},{"location":"utils/#Utilities","page":"Utilities","title":"Utilities","text":"","category":"section"},{"location":"utils/","page":"Utilities","title":"Utilities","text":"Misc functions needed in many applications. rescale scales an entire buffer, dBscale converts dB to amplitude, interp4 does 4-point interpolation, raisedcos is a masking waveform, midi2hz/hz2midi convert MIDI note numbers <-> Hz.","category":"page"},{"location":"utils/","page":"Utilities","title":"Utilities","text":"Synth.rescale\nSynth.dBscale\nSynth.interp4\nSynth.raisedcos\nSynth.midi2hz\nSynth.hz2midi\nSynth.easeinout\nSynth.curve\nSynth.Seg\nSynth.circular","category":"page"},{"location":"utils/#Synth.rescale","page":"Utilities","title":"Synth.rescale","text":"rescale(maxamp :: Real, samples :: AbstractArray) :: Vector{Float32}\n\nRescales the samples so that the maximum extent fits within the given maxamp (which must be positive). The renderer automatically rescales to avoid clamping.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.dBscale","page":"Utilities","title":"Synth.dBscale","text":"dBscale(::Real)\ndBscale(::Signal)\n\nConverts a dB value to a scaling factor\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.interp4","page":"Utilities","title":"Synth.interp4","text":"interp4(x, x1, x2, x3, x4)\n\nFour point interpolation.\n\nx is expected to be in the range [0,1].\n\nThis is a cubic function of x such that -\n\nf(-1) = x1\nf(0) = x2\nf(1) = x3\nf(2) = x4\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.raisedcos","page":"Utilities","title":"Synth.raisedcos","text":"raisedcos(x, overlap, scale=1.0f0)\n\nA \"raised cosine\" curve has a rising part that is shaped like cos(x-π/2)+1 and a symmetrically shaped falling part. If the overlap is 0.5, then there is no intervening portion between the rising and falling parts (x is in the range [0,1]). For overlap values less than 0.5, the portion between the rising and falling parts will be clamped to 1.0.\n\nFor example, raisedcos(x, 0.25) will give you a curve that will smoothly rise from 0.0 at x=0.0 to 1.0 at x=0.25, stay fixed at 1.0 until x = 0.75 and smoothly decrease to 0.0 at x=1.0.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.midi2hz","page":"Utilities","title":"Synth.midi2hz","text":"midi2hz(midi::Real)\nmidi2hz(::Signal)\n\nConverts a MIDI note number into a frequency using the equal tempered tuning.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.hz2midi","page":"Utilities","title":"Synth.hz2midi","text":"hz2midi(hz::Real)\nhz2midi(::Signal)\n\nConverts a frequency in Hz to its MIDI note number in the equal tempered tuning.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.easeinout","page":"Utilities","title":"Synth.easeinout","text":"easeinout(t::Float64)\n\nFor values of t in range [0.0,1.0], this curve rises smoothly from 0.0 and settles smoothly into 1.0. We're not usually interested in its values outside the [0.0,1.0] range.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.curve","page":"Utilities","title":"Synth.curve","text":"curve(segments :: Vector{Seg}; stop=false)\n\nMakes a piece-wise curve given a vector of segment specifications. Each Seg captures the start value, end value, duration of the segment, and the interpolation method to use in between.\n\nIf you pass true for stop, it means the curve will be done once all the segments are done. Otherwise the curve will yield the last value forever.\n\n\n\n\n\n","category":"function"},{"location":"utils/#Synth.Seg","page":"Utilities","title":"Synth.Seg","text":"Seg(v :: Real, dur :: Float64)\n\nA segment that holds the value v for the duration dur.\n\n\n\n\n\nSeg(v1 :: Real, v2 :: Real, dur :: Float64, interp::Symbol = :linear)\n\nConstructs a general segment that takes value from v1 to v2 over dur using the specified interpolator interp.\n\ninterp can take on one of [:linear, :exp, :cos, :harmonic]. The default interpolation is :linear.\n\n\n\n\n\n","category":"type"},{"location":"utils/#Synth.circular","page":"Utilities","title":"Synth.circular","text":"circular(v::AbstractArray{T}) :: Circular{T,AbstractArray{T}}\n\nMakes a circular array that handles the modulo calculations.\n\n\n\n\n\n","category":"function"},{"location":"design/#Design","page":"Design","title":"Design","text":"","category":"section"},{"location":"design/","page":"Design","title":"Design","text":"In Synth, you describe audio signals using signal constructors and combinators and finally pass them on to a renderer - either one that renders to a file or one that plays it back in real time.","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"A \"signal\" (represented by the abstract type Synth.Signal) therefore identifies the computation that produces the samples with the mathematical notion of a time-varying value that's sampled at a regular rate, known as the \"sampling rate\". ","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"note: Sampling rate\nThis is the number of audio samples per second. CDs uses 44.1KHz as the sampling rate. This package chooses 48KHz as the sampling rate by default wherever necessary.","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"A \"signal\" in this package is defined by its support for two methods –","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"done(s :: S, t, dt) :: Bool where {S <: Signal}\nvalue(S :: S, t, dt) :: Float32 where {S <: Signal}","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"The done method indicates whether a signal is finished at a given time or not. It is expected to obey the following constraints –","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"done(s, t, dt) == true implies done(s, t', dt) == true for all t  t.\ndone(s, t, dt) == false implies done(s, t', dt) == false for all t  t.","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"The value method computes the value of the signal s at the given time t. It too has a constraint, albeit a soft one – value(s, t, dt) == 0.0f0 for all t for which done(s, t, dt) == true. In some cases, value may choose to return a constant other than 0.0f0, but the idea is that the value calculation must not assume that only values of t for which done will produce false will be supplied. This soft constraint is so that done does not need to be called per sample by any render. It only needs to be called per \"frame\" - which is like 64 samples or 128 samples depending on the buffer length.","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"Additionally, value is expected to be called with a monotonic t argument in time steps of dt – i.e. t can either be the same as that of the previous call, or can advance by the given dt. Most signals do not need to account for repeated calls with same t since that can be handled by wrapping a concrete type as an fanout. ","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"The value method on a signal computes a single sample value. Having a function call to compute a single sample sounds like a significant overhead, but the way the types are organized and how Julia does a deep type specializing optimizing compilation pass on the entire call graph of a function implies that most of these calls get optimized away. When you compose signals and look at their type signature, you'll see how all the composition information is reflected in the resultant signal type and this is the information that's needed to optimize the value call on the composite signal. The value method implementation on a type also provides a boundary at which to perform such optimizations. Mostly, you as a user don't need to think about these optimizations.","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"note: Dynamic signals\nSome signals such as Synth.scheduler compose signals that are specified dynamically and therefore cannot completely produce inlined value implementations. Therefore there will be one step of dynamic dispatch happening within a scheduler's value implementation. However, since the dispatch is to another value method invocation (or done), and the type of the signal being dispatched for becomes known at that dynamic point, a compiled version of that entire call sub-tree will be used. A small number of such dynamic dispatched per value call therefore pose no threat to performance.","category":"page"},{"location":"design/","page":"Design","title":"Design","text":"note: Compilation cost\nWhat this package relies on is Julia's type specializing just-ahead-of-time compiler. This compilation pass can take a noticeable amount of time for modest sized functions. This means that a freshly composed signal that Julia has not seen at all will likely cause a stutter the first time it is run. For this reason, it is good to mark all the combinations under a test function that gets called once before you do any realtime performance. This compilation delay will not make a difference if you're just rendering to a file though.","category":"page"},{"location":"env/#Envelopes","page":"Envelopes","title":"Envelopes","text":"","category":"section"},{"location":"env/","page":"Envelopes","title":"Envelopes","text":"Shaping the amplitude contour of a signal is a common need and the envelope functions are there to help you with that. Of these, perhaps the most useful is adsr which can be live controlled in  addition to being of a pre-determined shape and duration.","category":"page"},{"location":"env/","page":"Envelopes","title":"Envelopes","text":"Synth.line\nSynth.expon\nSynth.adsr\nSynth.decay\nSynth.follow\nSynth.Gen","category":"page"},{"location":"env/#Synth.line","page":"Envelopes","title":"Synth.line","text":"line(v1 :: Real, duration_secs :: Real, v2 :: Real)\n\nMakes a signal that produces v1 for t < 0.0 and v2 for t > duration_secs. In between the two times, it produces a linearly varying value between v1 and v2. This signal is infinite in extent. Use clip to limit its extent.\n\n\n\n\n\n","category":"function"},{"location":"env/#Synth.expon","page":"Envelopes","title":"Synth.expon","text":"expon(v1 :: Real, duration_secs :: Real, v2 :: Real)\n\nSimilar to line, but does exponential interpolation from v1 to v2 over duration_secs. Note that both values must be > 0.0 for this to be valid. The resultant signal is infinite in extent. Use clip to limit its extent.\n\n\n\n\n\n","category":"function"},{"location":"env/#Synth.adsr","page":"Envelopes","title":"Synth.adsr","text":"adsr(suslevel :: Real, sus_secs :: Real;\n     attack_factor = 2.0, attack_secs = 0.002,\n     decay_secs = 0.01, release_secs = 0.2)\n\nMakes an \"attack-decay-sustain-release\" envelope. The decay and release phases are treated as exponential and the others stay linear. The arguments are arranged such that mostly you specify the suslevel and sus_secs, which control the amplitude and duration of a note controlled by the ADSR. The rest are given defaults that you can change if needed.\n\nsuslevel is the sustain level\nsus_secs is the duration of the sustain portion\nattack_factor determines the peak of the attack and multiplies the sustain level.\nattack_secs is the duration of the linear attack portion\ndecay_secs is the duration of the exponential decay portion after the attack.\nrelease_secs is the \"half life\" of the release portion of the envelope.\nrelease_factor is the number of \"releasesecs\" it takes to drop the amplitude to 0. When the amplitude drops below 1/32767, the signal will stop. If we let the decay happen at a steady logarithmic pace of a factor of 2 every `releasesecs, it can take a full 3 seconds for it to stop even whenreleasesecs == 0.2. This can cause computational cost to go up because voices will remain alive for longer without actually being audible. So we accelerate the drop instead of using a steady logarithmic drop velocity, so that the signal will end within aboutreleasefactor * releasesecsafter release phase begins. Thisreleasefactordefaults to 4. This \"acceleration\" tends to 0 as thereleasefactorbecomes larger. So if you strictly want thereleasesecsto be the \"half life\" of the signal, set this factor to be 15.0. Setting it to any value above 15.0 will cause the signal to linger on and decay at a slower rate than indicated byrelease_secs`.\n\n\n\n\n\n","category":"function"},{"location":"env/#Synth.decay","page":"Envelopes","title":"Synth.decay","text":"decay(rate :: Signal)\n\nProduces a decaying exponential signal with a \"half life\" determined by 1/rate. It starts with 1.0. The signal includes a short attack at the start to prevent glitchy sounds.\n\n\n\n\n\n","category":"function"},{"location":"env/#Synth.follow","page":"Envelopes","title":"Synth.follow","text":"follow(s :: Signal, rate :: Signal)\nfollow(s :: Signal, rate :: Real)\n\nFollows a signal on the rise and decays on the fall. This means if the input signal is an impulse, then  you'll get a series of exponential decays on each of the impulses.\n\n\n\n\n\n","category":"function"},{"location":"env/#Synth.Gen","page":"Envelopes","title":"Synth.Gen","text":"Gen(s :: Signal)\n\nA general wrapper for an arbitrary signal that can hide the signal type within underlying functions.\n\n\n\n\n\n","category":"type"},{"location":"music/#For-music","page":"For music","title":"For music","text":"","category":"section"},{"location":"music/","page":"For music","title":"For music","text":"Compound musical signals usually have some additional structure that is worthy of special support. At the moment, we support signals with regular beats driven on the falling edge of a sawtooth phasor.","category":"page"},{"location":"music/","page":"For music","title":"For music","text":"Synth.beats\nSynth.BeatGen\nSynth.genbeat","category":"page"},{"location":"music/#Synth.beats","page":"For music","title":"Synth.beats","text":"beats(tempo :: Signal, gen :: BeatGen; phase = 1.0f0, count = -1) :: Beats\nbeats(tempo :: Real, gen :: BeatGen; phase=1.0, count=-1) :: Beats\n\nGenerates beats using genbeat starting with the given phase. The default values are such that the very first sample produced is considered to be the start of a beat. If you need to start it a little later, supply a corresponding value of phase that's < 1.0.\n\n\n\n\n\n","category":"function"},{"location":"music/#Synth.BeatGen","page":"For music","title":"Synth.BeatGen","text":"abstract type BeatGen end\n\nMake a subtype of this type and define the genbeat method on it to use your own custom beat generation algorithm via beats.\n\n\n\n\n\n","category":"type"},{"location":"music/#Synth.genbeat","page":"For music","title":"Synth.genbeat","text":"genbeat(bg :: BeatGen,\n        phase :: AbstractFloat,\n        count :: Integer,\n        trigger :: Bool,\n        dphase :: AbstractFloat,\n        dt :: AbstractFloat) :: Union{Val{:end},Nothing,Signal}\n\nAbstract method to be implemented for BeatGen types for use with beats.\n\nphase is (usually) a number in the range [0.0,1.0] that indicates the phase within a beat.\ncount is the current beat count starting at 0 for the first beat.\ntrigger is true for the first call of every beat interval.\ndphase is the change in phase from previous value. The difference in phase values between this call and the previous.\ndt is the usual sampling interval.\n\nThis method is called for every sample, letting you add signals during any point within a beat cycle. The return value is expected nothing to indicate nothing to do but continue, Val(:end) to indicate the end of the sequence after which no genbeat call will be made, or a Signal to start playing at the time.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Realtime-playback","page":"Realtime playback","title":"Realtime playback","text":"","category":"section"},{"location":"rt/","page":"Realtime playback","title":"Realtime playback","text":"Methods that provide support for realtime playback as opposed to static file based rendering. The commonly used methods are play and play! (when using a synthesizer). For interactivity, see control (for UI to signal) and probe (for signal to UI).","category":"page"},{"location":"rt/","page":"Realtime playback","title":"Realtime playback","text":"Synth.startaudio\nSynth.synthesizer\nSynth.synthchan\nSynth.play!\nSynth.play\nSynth.control\nSynth.stop\nSynth.probe\nSynth.level\nSynth.scheduler\nSynth.schedule\nSynth.seq\nSynth.later","category":"page"},{"location":"rt/#Synth.startaudio","page":"Realtime playback","title":"Synth.startaudio","text":"startaudio(callback)\n\ncallback is a function that will be called like callback(sample_rate, readqueue, writequeue). sample_rate indicates the output sampling rate. readqueue and writequeue are Channels that accept either an audio buffer as a Vector{Float32} or Val(:done) to indicate completion of the audio process. The callback is expected to take! a buffer from the readqueue, fill it up and submit it to the writequeue using put!.\n\nWhen the audio generation is done, callback should put!(writequeue, Val(:done)) and break out of its generation loop and return.\n\nIt returns a function that can be called (without any arguments) to stop the audio processing thread. Make sure to start julia with a sufficient number of threads for this to work.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.synthesizer","page":"Realtime playback","title":"Synth.synthesizer","text":"synthesizer(commands::Channel{Tuple{Float64,Signal}}; blocksize=64)\n\nWraps startaudio such that you can send signals at arbitrary times to the given channel and the synthesizer will immediately start playing the signal. The first part of the tuple is expected to be a time stamp of arrival of event that triggers the signal. So in the event receiver, capture this time stamp upon entry by calling the time() function before doing anything else and use that value for the tuple.\n\nReturns a stop function which when called with no arguments will stop the synth.\n\nYou can use synthchan to make a channel.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.synthchan","page":"Realtime playback","title":"Synth.synthchan","text":"synthchan() :: Channel{Tuple{Float64, Signal}}\n\nMakes a channel suitable for use with synthesizer. You can then send signals to this channel using play! or in special cases directly using it like put!(time(), sig) where the time can be noted several steps earlier for a sense of immediacy.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.play!","page":"Realtime playback","title":"Synth.play!","text":"play!(commands :: Channel{Tuple{Float64, Signal}}, sig :: Signal)\nplay!(commands :: Channel{Tuple{Float64, Signal}}, sig :: Signal, t :: Float64)\n\nPlays the signal by adding it to the command queue of a synthesizer. When the t argument is omitted, it is taken to mean the \"current time\" in the absolute sense of time().\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.play","page":"Realtime playback","title":"Synth.play","text":"play(signal, duration_secs=Inf; blocksize=64)\n\nPlays the given signal on the default audio output in realtime for the given duration or till the signal ends, whichever happens earlier. Be careful about the signal level since in this case the signal can't be globally normalized.\n\nReturns a stop function (like with startaudio and synthesizer) which when called with no arguments will stop playback.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.control","page":"Realtime playback","title":"Synth.control","text":"control(chan :: Channel{Float32}, dezipper_interval = 0.04; initial = 0.0f0, samplingrate=48000) :: Control\ncontrol(dezipper_interval = 0.04; initial = 0.0f0, samplingrate = 48000) :: Control\n\nA \"control\" is a signal that is driven by values received on a given or created channel. The control will dezipper the value using a first order LPF and send it out as its value. The intention is to be able to bind a UI element that produces a numerical value as a signal that can be patched into the graph.\n\nIf c is a Control struct, you can set the value of the control using c[] = 0.5f0.\n\nClose the channel to mark the control signal as \"done\".\n\nnote: Channels and memory\nA control signal uses a channel to receive its values. This raises a question about the amount of memory that'll be consumed by using what looks like a system resource. Julia's channels cost about 416 bytes each, meaning a 1000 channels, which would be a pretty complex scenario to put it mildly, will be well under 1MB. Even if you have 1000 voices with 10 channels controlling each voice, the memory won't be significant (under 5MB) by 2025 standards.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.stop","page":"Realtime playback","title":"Synth.stop","text":"stop(c :: Control)\n\nStops the control signal. From the renderer's perspective, the control signal will switch to the \"done\" state. The control channel will close, causing any further put! calls to raise an exception. If you control the sustain of an adsr using a control signal, then stopping the control will basically end the ADSR envelope by switching it into \"release\" phase.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.probe","page":"Realtime playback","title":"Synth.probe","text":"probe(s :: Signal, chan :: Channel{Float32}, interval :: Float64 = 0.1; samplingrate = 48000) :: Probe\nprobe(s :: Signal, interval :: Float64 = 0.1; samplingrate = 48000) :: Probe\n\nA probe is a \"pass through\" signal transformer which periodically reports a reading of the signal to a channel. The channel may either be given or a new one can be created by the second variant. Since it is a pass-through, you can insert a probe at any signal point. A probe low-pass-filters the signal before sending it out the channel, so it won't be useful for signals that vary very fast. The default value has it sampling the signal every 40ms.\n\nThe channel can then be connected to a UI display widget that shows values as they come in on the channel.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.level","page":"Realtime playback","title":"Synth.level","text":"level(s::Signal; interval=0.015, refmin=1/(32767*32767), samplingrate=48000)\n\nComputes the smoothed dB level of a signal. The range is from 0 to about 90dB. \n\nrefmin is the tiniest sliver of sound intensity that can be registered. The default is set to a value appropriate for 16-bit sampled sound.\ninterval is the smoothing interval - i.e. the time constant of the first order filter that's applied on the square of the signal.\n\nrefmin determines the range since it is the floor of the signal that is 0dB. For the default value, the max ends up around 20log_10(32767) approx 90309textdB. A factor of two change in amplitude is a change in level of around 6.021 dB.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.scheduler","page":"Realtime playback","title":"Synth.scheduler","text":"scheduler(clk :: Signal) :: Scheduler\n\nCreates a \"scheduler\" which is itself a signal that can be composed with other signals and processors. The scheduler runs on its own  clock and sending Tuple{Float64,Signal} values on the .chan property will trigger those signals at the given times according to the clock. The scheduling is sample accurate.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.seq","page":"Realtime playback","title":"Synth.seq","text":"seq(clock :: Signal, triggers :: Vector{Tuple{Float64,Signal}})\n\nSequences the given signals in a virtual timeline determined by the given clock. Use clock_bpm to make such a clock.\n\n\n\n\n\n","category":"function"},{"location":"rt/#Synth.later","page":"Realtime playback","title":"Synth.later","text":"later(delay_secs :: Float64, s :: Signal)\n\nPostpones the signal by the given delaysecs. Note that this is not the same as a delay line where there is memory allocated to store some of the samples. The signal is not touched until `delaysecs` has passed, and the time value that the signal ends up seeing also does not span the period up to the delay.\n\n\n\n\n\n","category":"function"},{"location":"fx/#Effects","page":"Effects","title":"Effects","text":"","category":"section"},{"location":"fx/","page":"Effects","title":"Effects","text":"Synth.compress","category":"page"},{"location":"fx/#Synth.compress","page":"Effects","title":"Synth.compress","text":"compress(s :: Signal, k :: Signal; τ :: AbstractFloat = 0.03f0, samplingrate=48000)\n\nCompresses the signal using a dynamic compression algorithm.\n\ns is the signal to compress\nk is the amount of compression to apply. Must be positive. If k == 1, then  the compression applied can go up to a factor of half. The more the k, the more the compression that's applied for louder sounds.\nτ is the time constant (half life) over which the signal strength is measured to determine the adaptive compression.\n\n\n\n\n\n","category":"function"},{"location":"tx/#Transformers","page":"Transformers","title":"Transformers","text":"","category":"section"},{"location":"tx/","page":"Transformers","title":"Transformers","text":"These operators transform signals in some ways such as mapping ranges (linearmap and expmap), wave shaping (waveshape).","category":"page"},{"location":"tx/","page":"Transformers","title":"Transformers","text":"Synth.waveshape\nSynth.linearmap\nSynth.expmap","category":"page"},{"location":"tx/#Synth.waveshape","page":"Transformers","title":"Synth.waveshape","text":"waveshape(f, sig :: Signal)\nmap(f, sig :: Signal)\n\nMaps a function over the signal. The result is a signal. map and waveshape are aliases for signals.\n\n\n\n\n\n","category":"function"},{"location":"tx/#Synth.linearmap","page":"Transformers","title":"Synth.linearmap","text":"linearmap(a1 :: Real, a2 :: Real, b1 :: Real, b2 :: Real, s :: Signal)\n\nMaps the input signal from its range to a new range.\n\n\n\n\n\n","category":"function"},{"location":"tx/#Synth.expmap","page":"Transformers","title":"Synth.expmap","text":"expmap(a1 :: Real, a2 :: Real, b1 :: Real, b2 :: Real, s :: Signal)\n\nSimilar to the job of linearmap but does exponential interpolated mapping. This implies all four values and the signal value must be positive.\n\n\n\n\n\n","category":"function"},{"location":"gen/#Generators","page":"Generators","title":"Generators","text":"","category":"section"},{"location":"gen/","page":"Generators","title":"Generators","text":"Commonly used generators such as oscillators, phasor (i.e. positive sawtooth) and others. This list will grow a bit over time.","category":"page"},{"location":"gen/","page":"Generators","title":"Generators","text":"sinosc is sine wave oscillator, phasor is a sawtooth wave that can also be used as a periodic phase signal, noise is white noise and sample plays back a \"sample\".","category":"page"},{"location":"gen/","page":"Generators","title":"Generators","text":"Synth.sinosc\nSynth.phasor\nSynth.noise\nSynth.sample","category":"page"},{"location":"gen/#Synth.sinosc","page":"Generators","title":"Synth.sinosc","text":"sinosc(m :: Union{Real,Signal}, f :: Union{Real,Signal}; phase = 0.0)\n\nA \"sinosc\" is a sinusoidal oscillator whose frequency and amplitude can be varied (\"modulated\") over time. The f argument is expected to be a frequency in Hz units. m determines the amplitude and f the frequency in Hz. The phase named argument is a number in the range [0.0,1.0] determining the starting phase within the cycle.\n\nnote: Design\nAn earlier approach was to have the second argument be a phasor. However, the phasor argument always ended up being passed as phasor(freq) and so it made sense to fold the frequency into sinosc as the main control.  This made for a simpler use of sinosc, though a tad less general. So essentially sinosc(m, f) is equivalent to sinosc_v1(m, phasor(f)) where sinosc_v1 was the previous version.\n\n\n\n\n\n","category":"function"},{"location":"gen/#Synth.phasor","page":"Generators","title":"Synth.phasor","text":"phasor(f :: Real, phi0 = 0.0)\nphasor(f :: Signal, phi0 = 0.0)\n\nA \"phasor\" is a signal that goes from 0.0 to 1.0 linearly and then loops back to 0.0. This is useful in a number of contexts including wavetable synthesis where the phasor can be used to lookup the wavetable.\n\n\n\n\n\n","category":"function"},{"location":"gen/#Synth.noise","page":"Generators","title":"Synth.noise","text":"noise(rng :: AbstractRNG, amp :: Signal)\nnoise(rng :: AbstractRNG, amp :: Real)\n\nAmplitude modulatable white noise generator.\n\n\n\n\n\nnoise(rng :: AbstractRNG, amp :: Signal)\nnoise(rng :: AbstractRNG, amp :: Real)\n\nAmplitude modulatable white noise generator.\n\n\n\n\n\n","category":"function"},{"location":"gen/#Synth.sample","page":"Generators","title":"Synth.sample","text":"sample(samples :: Vector{Float32}; looping = false, loopto = 1.0) \nsample(filename :: AbstractString; looping = false, loopto = 1.0, samplingrate=48000.0f0)\n\nProduces a sampled signal which samples from the given array as a source. It starts from the beginning and goes on until the end of the array, but can be asked to loop back to a specified point after that.\n\nThe loopto argument is specified relative (i.e. scaled) to the length of the samples vector. So if you want to jump back to the middle, you give 0.5 as the loopto value.\n\nCurrently sample rate conversion is not supported, though that is a feature that must be added at some point.\n\n\n\n\n\n","category":"function"},{"location":"#Synth.jl-Documentation","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"","category":"section"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"Synth.jl provides a library of signal generators and transformers in a highly compositional form suitable for musical applications. The Signal type is intended to model processes that evolve in time and which could be finite in extent. ","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"For example sinosc(0.5, 250.0) is a sine wave oscillator that oscillates at 250Hz with an amplitude of 0.5, forever, and sinosc(0.5, 250.0 + sinosc(100.0, 250.0)) gives you a frequency modulated sine oscillation and you can impose an envelope on it like this – sinosc(adsr(0.5, 1.0), 250.0 + sinosc(100.0, 250.0)) – which makes it finite in duration. Most operators can be composed in this manner, usually resulting in fairly efficient code as well. See the Models section for some other simple signal combinations such as Synth.Models.basicvocoder.","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"The above constructed finite extent signal can be rendered to a SampledSignals.SampleBuf using render like this –","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"v = render(sinosc(adsr(0.5, 1.0), 250.0 + sinosc(100.0, 250.0)))","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"(Pass an explicit duration if it's an infinite extent signal or use Synth.play.)","category":"page"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"Signals can be rendered to SampleBuf buffers, to raw Float32 files or in real time to the computer's sound output using play. There is also some minimal support for stereo signals.","category":"page"},{"location":"#The-Signal-type","page":"Synth.jl Documentation","title":"The Signal type","text":"","category":"section"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"Synth.Signal","category":"page"},{"location":"#Synth.Signal","page":"Synth.jl Documentation","title":"Synth.Signal","text":"abstract type Signal end\n\nA Signal represents a process that can be asked for a value for every tick of a clock. We use it here to represent processes that produce audio and control signals to participate in a \"signal flow graph\". While mathematically signals can be treated as though they were infinite in duration, signals are in practice finite in duration for both semantic and efficiency reasons (ex: managing voices as a constrained resource).\n\nTo construct signals and to wire them up in a graph, use the constructor functions provided rather than the structure constructors directly.\n\nThe protocol for a signal is given by two functions with the following signatures –\n\ndone(s :: Signal, t, dt) :: Bool\nvalue(s :: Signal, t, dt) :: Float32\n\nAs long as you implement these two methods, you can define your own subtype of Signal and use it with the library.\n\nThe renderer will call done to check whether a signal has completed and if not, will call value to retrieve the next value. The contract with each signal type is that even if value is called for a time after the signal is complete, it should return sample value 0.0f0 or a value appropriate for the type of signal. This is so that done can be called per audio frame rather than per sample.\n\nAddition, subtraction and multiplication operations are available to combine signals and numbers. Currently signals are single channel only.\n\nChoice of representation\n\nA number of approaches are used in computer music synth systems -\n\nBlocks and wires paradigm: ... where blocks represent signal processing modules and wires represent connections and signal flow between these modules. Even within this paradigm there are different semantics to how the signal flow is handled, from asynchronous/non-deterministic, to fully deterministic flow, to buffer-wise computation versus sample-wise computation. The WebAudioAPI, for example, takes this approach and performs buffer-wise computation in blocks of 128 samples. It is rare to find a synth library that works sample-wise in this mode.\nFunctional: ... where signals are mathematical constructs that can be combined using operators to construct new signals. Usually this paradigm manifests as a textual programming language, like SuperCollider and Chuck (which has elements of the above approach too).\n\nThe approach taken in this library is to combine the notion of a signal with the computation that produces the signal - a rough analog of \"constructive real numbers\". In other words, a \"signal\" – i.e. a stream of values regularly spaced in time – is identified with a computation that produces the stream.\n\nThis permits manipulating signals like mathematical objects that can be combined, while modelling \"signal flow\" via ordinary functions in programming that call other functions recursively. Without further thought, this approach will only permit \"signal flow trees\", where the output of a processing step can only be fed into a single input due to the nature of function composition being used to construct the signal flow pattern. However, with the fanout operator, it becomes possible to reuse a signal as input for more than one processing block, extending the scope to include \"signal flow DAGs\". The feedback operator further extends this possibility through late binding of signal connections to permit loops in the graph, truly getting us \"signal flow graphs\" that can support feedback loops, albeit with a single sample delay.\n\nThe library exploits Julia's \"optimizing just-ahead-of-time compilation\" to describe each signal computation function in a per-sample fashion so that sample frames can be computed efficiently by the renderer. In other languages including AoT compiled languages like C, this combination of simplicity of API with high performance will be very hard to get. In dynamic languages, the function call overhead is even worse and not easily eliminated due to weak type systems. You'll notice how the rich type information about how a signal was constructed is maintained in the final result so that the renderer can compile it down to efficient code, often eliminating intermediate function calls.\n\nRealtime usage necessitates some amount of dynamic dispatch, but it is still possible to mark boundaries whether the type knowledge can help create efficient code.\n\nThe end result of all this is that you can combine signals like ordinary math and expect complex signal flow graphs to work efficiently, even in realtime.\n\n\n\n\n\n","category":"type"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"The definition of Signal treats signal generators and transformers like \"values\" which can be operated on using ordinary arithmetic +, - and *.","category":"page"},{"location":"#Models","page":"Synth.jl Documentation","title":"Models","text":"","category":"section"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"Modules = [Synth.Models]\nOrder   = [:function, :type]","category":"page"},{"location":"#Synth.Models.additive","page":"Synth.jl Documentation","title":"Synth.Models.additive","text":"additive(f0,\n         amps :: AbstractVector{Union{Real,Signal}},\n         detune_factor :: Signal = konst(1.0f0))\n\nSimple additive synthesis. amps is a vector of Float32 or a vector of signals. f0 is a frequency value or a signal that evaluates to the frequency. The function constructs a signal with harmonic series based on f0 as the fundamental frequency and amplitudes determined by the array amps.\n\n\n\n\n\n","category":"function"},{"location":"#Synth.Models.basicvocoder-NTuple{4, Any}","page":"Synth.jl Documentation","title":"Synth.Models.basicvocoder","text":"basicvocoder(sig, f0, N, fnew; bwfactor = 0.2, bwfloor = 20.0)\n\nA simple vocoder for demo purposes. Takes N evenly spaced frequencies k f_0 and moves them over to a new set of frequencies k f_textnew using a heterodyne filter.  The bwfactor setting gives the fraction of the inter-frequency bandwidth to filter in. The bandwidth has a floor given by bwfloor in Hz.\n\n\n\n\n\n","category":"method"},{"location":"#Synth.Models.chirp-NTuple{4, Any}","page":"Synth.jl Documentation","title":"Synth.Models.chirp","text":"chirp(amp, startfreq, endfreq, dur;\n      shapename::Union{Val{:line},Val{:expon}} = Val(:line))\n\nA \"chirp\" is a signal whose frequency varies from a start value to  a final value over a period of time. The shape of the change can be controlled using the shapename keyword argument.\n\n\n\n\n\n","category":"method"},{"location":"#Synth.Models.fm","page":"Synth.jl Documentation","title":"Synth.Models.fm","text":"fm(carrier, modulator, index, amp = konst(1.0f0))\n\nBasic FM synth module. carrier is the carrier frequency that can itself be a signal. modulator is the modulation frequency and index is the extent of modulation. amp, if given decides the final amplitude. All of them can vary over time.\n\nExample\n\nplay(fm(220.0f0, 550.0f0, 100.0f0), 5.0)\n\n\n\n\n\n","category":"function"},{"location":"#Synth.Models.snare-Tuple{Real}","page":"Synth.jl Documentation","title":"Synth.Models.snare","text":"snare(dur::Real; rng = MersenneTwister(1234))\n\nVery simple snare hit where the dur is the \"half life\" of the snare's decay. Just amplitude modulates some white noise.\n\n\n\n\n\n","category":"method"},{"location":"#Synth.Models.tone-Tuple{Any, Any, Any}","page":"Synth.jl Documentation","title":"Synth.Models.tone","text":"tone(amp, freq, duration; attack_factor = 2.0, attack_secs = 0.005, decay_secs = 0.05, release_secs = 0.2)\n\nA simple sine tone modulator by an ADSR envelope. amp is the amplitude of the sustain portion, freq is the Hz value of the frequency of the tone and duration is the duration in seconds of the sustain portion.\n\nEnvelope characteristics\n\nattack_factor - the factor (usually > 1.0) that multiplies the amplitude value to  determine the peak of the attack portion of the envelope.\nattack_secs - the duration of the attack portion. This should be kept short in general.\ndecay_secs - the duration of the portion of the envelope where it decays from the peak attack value down to the sustain level.\nrelease_secs - the \"half life\" of the release portion of the envelope. Over this time, the amplitude of the signal will decay by a factor of 2.\n\n\n\n\n\n","category":"method"},{"location":"#Index","page":"Synth.jl Documentation","title":"Index","text":"","category":"section"},{"location":"","page":"Synth.jl Documentation","title":"Synth.jl Documentation","text":"","category":"page"}]
}
